{
  "paths": [
    {
      "type": "file",
      "value": "index.md"
    },
    {
      "type": "dir",
      "name": "1-Machine Learning",
      "children": [
        {
          "type": "file",
          "value": "1-Machine Learning/1-Convolution.md"
        },
        {
          "type": "file",
          "value": "1-Machine Learning/2-Embedding.md"
        },
        {
          "type": "file",
          "value": "1-Machine Learning/3-Preprocessing.md"
        },
        {
          "type": "file",
          "value": "1-Machine Learning/4-Categorizer.md"
        },
        {
          "type": "file",
          "value": "1-Machine Learning/5-LSTM RNN CNN.md"
        },
        {
          "type": "file",
          "value": "1-Machine Learning/6-Sentiment Modeling.md"
        },
        {
          "type": "file",
          "value": "1-Machine Learning/7-Bagging and Boosting.md"
        },
        {
          "type": "file",
          "value": "1-Machine Learning/8-Chatbot.md"
        }
      ]
    },
    {
      "type": "dir",
      "name": "2-WebRTC",
      "children": [
        {
          "type": "file",
          "value": "2-WebRTC/APIs.md"
        },
        {
          "type": "file",
          "value": "2-WebRTC/Mechanism.md"
        },
        {
          "type": "file",
          "value": "2-WebRTC/Signaling.md"
        }
      ]
    },
    {
      "type": "dir",
      "name": "3-Azure",
      "children": [
        {
          "type": "file",
          "value": "3-Azure/App Service Warmer.md"
        },
        {
          "type": "file",
          "value": "3-Azure/Deployment.md"
        }
      ]
    },
    {
      "type": "dir",
      "name": "4-Zoom",
      "children": [
        {
          "type": "file",
          "value": "4-Zoom/API 사용기.md"
        }
      ]
    },
    {
      "type": "dir",
      "name": "5-Flutter",
      "children": [
        {
          "type": "file",
          "value": "5-Flutter/1-Setup.md"
        },
        {
          "type": "file",
          "value": "5-Flutter/2-Widget.md"
        },
        {
          "type": "file",
          "value": "5-Flutter/3-Assets.md"
        },
        {
          "type": "file",
          "value": "5-Flutter/4-Http Request.md"
        }
      ]
    },
    {
      "type": "dir",
      "name": "99-ETC",
      "children": [
        {
          "type": "file",
          "value": "99-ETC/CloudStorage.md"
        },
        {
          "type": "file",
          "value": "99-ETC/GithubPage.md"
        },
        {
          "type": "file",
          "value": "99-ETC/MQvsKafka.md"
        }
      ]
    }
  ],
  "contents": [
    {
      "path": "index.md",
      "url": "index.html",
      "content": "###Profile\n```\nFull stack software engineer\n\n클라우드 기반(AWS / GCP / Azure) 서비스 운영\nSpring Boot, Node.js 백엔드 개발\nVue.js, React.js, Flutter 프론트 개발\n```\n\n###Projects\n__T Sphere__\n```\n- SKT 거점 오피스 회의실/좌석 예약 시스템\n- 회의실 및 좌석을 예약할 수 있는 kiosk / mobile 앱 개발\n- Azure, Spring Boot, Vue.js, Flutter, Keycloak based\n```\n\n__Smart Office 얼굴 출입 시스템__\n```\n- SKT 남산사옥에 적용된 얼굴 출입 시스템\n- Realnetworks의 얼굴 인식 API를 사용하여 사진 등록 서비스 개발\n- Hikvision의 안면 인식 카메라를 이용하여 출입자 인증 서비스 개발\n- Spring Boot, Vue.js based\n```\n\n__Cello Square__\n```\n- 삼성 SDS 차세대 물류 시스템\n- 대용량 정산 데이터 프로세싱 서비스 구축 \n- Node.js, AWS Lambda, Vue.js based\n```\n\n__S-Patch__\n```\n- 핸드폰 심전도 측정 솔루션\n- 부착형 측정기에서 핸드폰으로 데이터 전송 및 병원 시스템과 연동\n- Android, Spring Boot based\n```\n\n__Maxigent__\n```\n- 인프라 네트워크 모니터링 솔루션\n- Transform JavaFX to Node.js\n```\n\n###Certificates\n```\n- OPIC AL\n- Samsung Software Exam Professional\n- DAsP\n- SQLD\n``` \n\n###Education\n```\n2007-08 ~ 2013-12\n학사 University of Illinois at Urbana Champaign\n```\n\n###Github\n```\n- https://github.com/CheolminConanShin\n- https://github.com/ConanShin\n```",
      "html": "<p>###Profile</p>\n<pre><code>Full stack software engineer\n\n클라우드 기반(AWS / GCP / Azure) 서비스 운영\nSpring Boot, Node.js 백엔드 개발\nVue.js, React.js, Flutter 프론트 개발\n</code></pre>\n<p>###Projects\n<strong>T Sphere</strong></p>\n<pre><code>- SKT 거점 오피스 회의실/좌석 예약 시스템\n- 회의실 및 좌석을 예약할 수 있는 kiosk / mobile 앱 개발\n- Azure, Spring Boot, Vue.js, Flutter, Keycloak based\n</code></pre>\n<p><strong>Smart Office 얼굴 출입 시스템</strong></p>\n<pre><code>- SKT 남산사옥에 적용된 얼굴 출입 시스템\n- Realnetworks의 얼굴 인식 API를 사용하여 사진 등록 서비스 개발\n- Hikvision의 안면 인식 카메라를 이용하여 출입자 인증 서비스 개발\n- Spring Boot, Vue.js based\n</code></pre>\n<p><strong>Cello Square</strong></p>\n<pre><code>- 삼성 SDS 차세대 물류 시스템\n- 대용량 정산 데이터 프로세싱 서비스 구축 \n- Node.js, AWS Lambda, Vue.js based\n</code></pre>\n<p><strong>S-Patch</strong></p>\n<pre><code>- 핸드폰 심전도 측정 솔루션\n- 부착형 측정기에서 핸드폰으로 데이터 전송 및 병원 시스템과 연동\n- Android, Spring Boot based\n</code></pre>\n<p><strong>Maxigent</strong></p>\n<pre><code>- 인프라 네트워크 모니터링 솔루션\n- Transform JavaFX to Node.js\n</code></pre>\n<p>###Certificates</p>\n<pre><code>- OPIC AL\n- Samsung Software Exam Professional\n- DAsP\n- SQLD\n</code></pre>\n<p>###Education</p>\n<pre><code>2007-08 ~ 2013-12\n학사 University of Illinois at Urbana Champaign\n</code></pre>\n<p>###Github</p>\n<pre><code>- https://github.com/CheolminConanShin\n- https://github.com/ConanShin\n</code></pre>\n",
      "id": 0
    },
    {
      "path": "1-Machine Learning/1-Convolution.md",
      "url": "1-Machine Learning/1-Convolution.html",
      "content": "2021-01-22\n===\n###### tags: `Convolution` `Dialation`\n\n#### dropout\n과적합 방지를 위한 정규화 방법, rate 파라미터의 비율만큼 dropout이 적용된다.\n\n#### convolution(합성곱 연산)\n![](https://i.imgur.com/Yf0pUmr.png)\n\n#### dialation_rate\n![](https://qph.fs.quoracdn.net/main-qimg-d9025e88d7d792e26f4040b767b25819)\n- 주변 픽셀의 Contextual Information을 고려하기 위함\n- kernel size(receptive field)를 늘려서 주변 픽셀을 고려하기 되면 연산 복잡도가 증가됨\n- 0 padding을 통해 연산 복잡도는 줄이고 주변을 고려할 수 있는 convolution layer를 생성\n\n#### strides\n필터가 적용되는 위치의 간격\n\n#### receptive field\nkernel_size = output을 만들어내는 영역\n\ndownsampling/upsampling: 데이터의 차원을 변경시켜 이미지를 압축하거나 늘리는 방식\n\npooling/unpooling\n- pooling: 가로 세로 방향의 공간을 줄이는 연산, 에를 들어 최대 풀링 2X2의 경우 2X2 사이즈 내에서 최값을 뽑아낸다. \n- unpooling: 풀링의 반대, 같은 값으로 채우거나 0으로 채우는 등 여러 방법이 있다.\n \ndata format:\n- batch: 몇장의 사진을 이번 트레이닝에 input으로 사용할 것인가\n- channel: 사진은 RGB로 3개의 채널을 가짐 (데이터의 속성 갯수)\n\npadding='same' : input size와 같도록 맞춰준다 \n\nconv1D\n- :exclamation:우리가 헷갈렸던 부분 : 1D짜리 convolution을 적용한다고 생각했는데 (filter size가 1 * n 이라 생각했는데)\n- 실제 : convolution 방향이 1D였던 것(가로 방향으로만 convolution하도록 filter size가 자동으로 정해짐) \n\n```python=\ninputs = tf.keras.Input(shape = (1, 28, 28)) # (1)\ndropout = tf.keras.layers.Dropout(rate=0.2)(inputs)\nconv = tf.keras.layers.Conv1D(10, 3, padding='same', activation=tf.nn.relu)(inputs) # (2)\n```\n1. input size는 28*28\n2. input이 1D convolution을 통과하여 (28-2)*1 이 되고,  padding='same' 옵션을 주었으니 input size와 같아지도록 padding을 추가하여 28*1이 됨. 채널 10이므로 28 * 1 * 10\n\n",
      "html": "<h1 id=\"2021-01-22\">2021-01-22 <a class=\"heading-anchor-permalink\" href=\"#2021-01-22\">#</a></h1>\n<h6 id=\"tags%3A-convolution-dialation\">tags: <code>Convolution</code> <code>Dialation</code> <a class=\"heading-anchor-permalink\" href=\"#tags%3A-convolution-dialation\">#</a></h6>\n<h4 id=\"dropout\">dropout <a class=\"heading-anchor-permalink\" href=\"#dropout\">#</a></h4>\n<p>과적합 방지를 위한 정규화 방법, rate 파라미터의 비율만큼 dropout이 적용된다.</p>\n<h4 id=\"convolution(%ED%95%A9%EC%84%B1%EA%B3%B1-%EC%97%B0%EC%82%B0)\">convolution(합성곱 연산) <a class=\"heading-anchor-permalink\" href=\"#convolution(%ED%95%A9%EC%84%B1%EA%B3%B1-%EC%97%B0%EC%82%B0)\">#</a></h4>\n<p><img src=\"https://i.imgur.com/Yf0pUmr.png\" alt=\"\"></p>\n<h4 id=\"dialation_rate\">dialation_rate <a class=\"heading-anchor-permalink\" href=\"#dialation_rate\">#</a></h4>\n<p><img src=\"https://qph.fs.quoracdn.net/main-qimg-d9025e88d7d792e26f4040b767b25819\" alt=\"\"></p>\n<ul>\n<li>주변 픽셀의 Contextual Information을 고려하기 위함</li>\n<li>kernel size(receptive field)를 늘려서 주변 픽셀을 고려하기 되면 연산 복잡도가 증가됨</li>\n<li>0 padding을 통해 연산 복잡도는 줄이고 주변을 고려할 수 있는 convolution layer를 생성</li>\n</ul>\n<h4 id=\"strides\">strides <a class=\"heading-anchor-permalink\" href=\"#strides\">#</a></h4>\n<p>필터가 적용되는 위치의 간격</p>\n<h4 id=\"receptive-field\">receptive field <a class=\"heading-anchor-permalink\" href=\"#receptive-field\">#</a></h4>\n<p>kernel_size = output을 만들어내는 영역</p>\n<p>downsampling/upsampling: 데이터의 차원을 변경시켜 이미지를 압축하거나 늘리는 방식</p>\n<p>pooling/unpooling</p>\n<ul>\n<li>pooling: 가로 세로 방향의 공간을 줄이는 연산, 에를 들어 최대 풀링 2X2의 경우 2X2 사이즈 내에서 최값을 뽑아낸다.</li>\n<li>unpooling: 풀링의 반대, 같은 값으로 채우거나 0으로 채우는 등 여러 방법이 있다.</li>\n</ul>\n<p>data format:</p>\n<ul>\n<li>batch: 몇장의 사진을 이번 트레이닝에 input으로 사용할 것인가</li>\n<li>channel: 사진은 RGB로 3개의 채널을 가짐 (데이터의 속성 갯수)</li>\n</ul>\n<p>padding=‘same’ : input size와 같도록 맞춰준다</p>\n<p>conv1D</p>\n<ul>\n<li>:exclamation:우리가 헷갈렸던 부분 : 1D짜리 convolution을 적용한다고 생각했는데 (filter size가 1 * n 이라 생각했는데)</li>\n<li>실제 : convolution 방향이 1D였던 것(가로 방향으로만 convolution하도록 filter size가 자동으로 정해짐)</li>\n</ul>\n<pre><code class=\"language-python=\">inputs = tf.keras.Input(shape = (1, 28, 28)) # (1)\ndropout = tf.keras.layers.Dropout(rate=0.2)(inputs)\nconv = tf.keras.layers.Conv1D(10, 3, padding='same', activation=tf.nn.relu)(inputs) # (2)\n</code></pre>\n<ol>\n<li>input size는 28*28</li>\n<li>input이 1D convolution을 통과하여 (28-2)<em>1 이 되고,  padding=‘same’ 옵션을 주었으니 input size와 같아지도록 padding을 추가하여 28</em>1이 됨. 채널 10이므로 28 * 1 * 10</li>\n</ol>\n",
      "id": 1
    },
    {
      "path": "1-Machine Learning/2-Embedding.md",
      "url": "1-Machine Learning/2-Embedding.html",
      "content": "2021-01-28\n===\n###### tags: `Embedding`\n\n\n### Word Embedding Layer를 학습시키는 방법\n1. CBow: 주변의 단어(window size)로 하나의 단어를 추측하는 기법\n2. Skip-gram: 하나의 단어로 주변 단어들을 추측하는 기법\n```\n입력층 [1 * 단어 벡터 길이] * 가중치 [단어 벡터 길이 * 은닉층 길이] = 은닉층 [1 * 은닉층 길이]\n은닉층 [1 * 은닉층 길이] * 가중치 [은닉층 길이 * 단어 벡터 길이] = 출력층 [1 * 단어 벡터 길이]\n```\n\n### Skip-gram sample\n\n```python=\nimport sys\nsys.path.append('..')\nimport numpy as np\nfrom common.layers import MatMul, SoftmaxWithLoss\n\n\nclass SimpleSkipGram:\n    def __init__(self, vocab_size, hidden_size):\n        V, H = vocab_size, hidden_size\n\n        # 가중치 초기화\n        W_in = 0.01 * np.random.randn(V, H).astype('f')\n        W_out = 0.01 * np.random.randn(H, V).astype('f')\n\n        # 계층 생성\n        self.in_layer = MatMul(W_in)\n        self.out_layer = MatMul(W_out)\n        self.loss_layer1 = SoftmaxWithLoss()\n        self.loss_layer2 = SoftmaxWithLoss()\n\n        # 모든 가중치와 기울기를 리스트에 모은다.\n        layers = [self.in_layer, self.out_layer]\n        self.params, self.grads = [], []\n        for layer in layers:\n            self.params += layer.params\n            self.grads += layer.grads\n\n        # 인스턴스 변수에 단어의 분산 표현을 저장한다.\n        self.word_vecs = W_in\n\n    def forward(self, contexts, target):\n        h = self.in_layer.forward(target)\n        s = self.out_layer.forward(h)\n        l1 = self.loss_layer1.forward(s, contexts[:, 0])\n        l2 = self.loss_layer2.forward(s, contexts[:, 1])\n        loss = l1 + l2\n        return loss\n\n    def backward(self, dout=1):\n        dl1 = self.loss_layer1.backward(dout)\n        dl2 = self.loss_layer2.backward(dout)\n        ds = dl1 + dl2\n        dh = self.out_layer.backward(ds)\n        self.in_layer.backward(dh)\n        return None\n```",
      "html": "<h1 id=\"2021-01-28\">2021-01-28 <a class=\"heading-anchor-permalink\" href=\"#2021-01-28\">#</a></h1>\n<h6 id=\"tags%3A-embedding\">tags: <code>Embedding</code> <a class=\"heading-anchor-permalink\" href=\"#tags%3A-embedding\">#</a></h6>\n<h3 id=\"word-embedding-layer%EB%A5%BC-%ED%95%99%EC%8A%B5%EC%8B%9C%ED%82%A4%EB%8A%94-%EB%B0%A9%EB%B2%95\">Word Embedding Layer를 학습시키는 방법 <a class=\"heading-anchor-permalink\" href=\"#word-embedding-layer%EB%A5%BC-%ED%95%99%EC%8A%B5%EC%8B%9C%ED%82%A4%EB%8A%94-%EB%B0%A9%EB%B2%95\">#</a></h3>\n<ol>\n<li>CBow: 주변의 단어(window size)로 하나의 단어를 추측하는 기법</li>\n<li>Skip-gram: 하나의 단어로 주변 단어들을 추측하는 기법</li>\n</ol>\n<pre><code>입력층 [1 * 단어 벡터 길이] * 가중치 [단어 벡터 길이 * 은닉층 길이] = 은닉층 [1 * 은닉층 길이]\n은닉층 [1 * 은닉층 길이] * 가중치 [은닉층 길이 * 단어 벡터 길이] = 출력층 [1 * 단어 벡터 길이]\n</code></pre>\n<h3 id=\"skip-gram-sample\">Skip-gram sample <a class=\"heading-anchor-permalink\" href=\"#skip-gram-sample\">#</a></h3>\n<pre><code class=\"language-python=\">import sys\nsys.path.append('..')\nimport numpy as np\nfrom common.layers import MatMul, SoftmaxWithLoss\n\n\nclass SimpleSkipGram:\n    def __init__(self, vocab_size, hidden_size):\n        V, H = vocab_size, hidden_size\n\n        # 가중치 초기화\n        W_in = 0.01 * np.random.randn(V, H).astype('f')\n        W_out = 0.01 * np.random.randn(H, V).astype('f')\n\n        # 계층 생성\n        self.in_layer = MatMul(W_in)\n        self.out_layer = MatMul(W_out)\n        self.loss_layer1 = SoftmaxWithLoss()\n        self.loss_layer2 = SoftmaxWithLoss()\n\n        # 모든 가중치와 기울기를 리스트에 모은다.\n        layers = [self.in_layer, self.out_layer]\n        self.params, self.grads = [], []\n        for layer in layers:\n            self.params += layer.params\n            self.grads += layer.grads\n\n        # 인스턴스 변수에 단어의 분산 표현을 저장한다.\n        self.word_vecs = W_in\n\n    def forward(self, contexts, target):\n        h = self.in_layer.forward(target)\n        s = self.out_layer.forward(h)\n        l1 = self.loss_layer1.forward(s, contexts[:, 0])\n        l2 = self.loss_layer2.forward(s, contexts[:, 1])\n        loss = l1 + l2\n        return loss\n\n    def backward(self, dout=1):\n        dl1 = self.loss_layer1.backward(dout)\n        dl2 = self.loss_layer2.backward(dout)\n        ds = dl1 + dl2\n        dh = self.out_layer.backward(ds)\n        self.in_layer.backward(dh)\n        return None\n</code></pre>\n",
      "id": 2
    },
    {
      "path": "1-Machine Learning/3-Preprocessing.md",
      "url": "1-Machine Learning/3-Preprocessing.html",
      "content": "2021-02-04\n===\n\n###### tags: `전처리` `preprocessing`\n\n#### 1. 불용어 제거\n``` python\ndef preprocessing( review, remove_stopwords = False ): \n    # 불용어 제거는 옵션으로 선택 가능하다.\n    \n    # 1. HTML 태그 제거\n    review_text = BeautifulSoup(review, \"html5lib\").get_text()\t\n\n    # 2. 영어가 아닌 특수문자들을 공백(\" \")으로 바꾸기\n    review_text = re.sub(\"[^a-zA-Z]\", \" \", review_text)\n\n    # 3. 대문자들을 소문자로 바꾸고 공백단위로 텍스트들 나눠서 리스트로 만든다.\n    words = review_text.lower().split()\n\n    if remove_stopwords: \n        # 4. 불용어들을 제거\n    \n        #영어에 관련된 불용어 불러오기\n        stops = set(stopwords.words(\"english\"))\n        # 불용어가 아닌 단어들로 이루어진 새로운 리스트 생성\n        words = [w for w in words if not w in stops]\n        # 5. 단어 리스트를 공백을 넣어서 하나의 글로 합친다.\t\n        clean_review = ' '.join(words)\n\n    else: # 불용어 제거하지 않을 때\n        clean_review = ' '.join(words)\n\n    return clean_review\n```\n\n#### 2. 단어를 단어사전을 사용해서 인덱스로 벡터화\n``` python\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(clean_train_reviews)\ntext_sequences = tokenizer.texts_to_sequences(clean_train_reviews)\n```\n#### 3. 문장 길이 동기화\n``` python\nword_vocab = tokenizer.word_index\nword_vocab[\"<PAD>\"] = 0\n\ndata_configs = {}\ndata_configs['vocab'] = word_vocab\ndata_configs['vocab_size'] = len(word_vocab)\n\nMAX_SEQUENCE_LENGTH = 174 \ntrain_inputs = pad_sequences(text_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n```\n* Median 산출\n* 중간값에 맞추어 문장 길이 변환\n* 긴 문장은 후반부 생략\n* 짧은 문장은 패딩으로 채우기 \n#### 4. 전처리 후 데이터 저장\n    \n#### 불용어 제거해서 히스토그램 찍어보기\n``` python\nword_size = [len(r.split()) for r in clean_train_reviews]\nnp.median(word_size)\n\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(15,10))\nplt.hist(word_size, bins=50, facecolor='r', label='train')\n```\n![](https://i.imgur.com/TIsvbgs.png)\n\n---\n\n###### tags: `모델링` `modeling`\n\n\nword index ? tf-idf? 둘 중 뭐써야함?\n\n### Tf-IDF Vectorizer\n:question: 왜 analyzer = 'char'로 주지..? 왜 'word'로 준거랑 차이가 없지..? SHIIITTT!!\n\n#### TEST\n* analyzer=\"char\" & ngram_range=(1,2): 0.782800\n* analyzer=\"char\" & ngram_range=(1,3): 0.859800\n* analyzer=\"char\" & ngram_range=(1,7): 0.850800\n* analyzer=\"word\" & ngram_range=(1,2): 0.887600\n\n`vectorizer = TfidfVectorizer(min_df = 0.0, analyzer=\"char\", sublinear_tf=True, ngram_range=(1,3), max_features=5000) \n`\n\n\nTfidfVectorizer 파라미터 정리\n* min-df : 설정한 값 이상 등장하는 단어만 등록, 단어의 등장횟수가 아니라 문서의 수\n* analyzer : 단어 단위로 볼지 문장 단위로 볼지\n* ngram_range : 문자 혹은 단어의 묶음을 처리하는 범위, 단어를 기준으로 하고 (1, 1)로 놓았을 경우 벡터라이저와 같은 결과를 보임(단어 하나씩만 처리하기 때문) (1,2)로 놓았을 경우 go, go to 등이 개별 단어로 처리된다. 묶여야 의미가 살아나는 표현들을 처리하기 위한 파리미터\n* max_feature : 각 벡터의 최대 길이를 처리\n* sublinear_tf : 단어의 빈도 수에 대한 스무딩 여부, 로그값으로 변환해 값을 완만하게 처리\n``` python\nimport numpy as np \ndef sublinear_func(input): \n    result = 1 + np.log(input) \n    return result\n```",
      "html": "<h1 id=\"2021-02-04\">2021-02-04 <a class=\"heading-anchor-permalink\" href=\"#2021-02-04\">#</a></h1>\n<h6 id=\"tags%3A-%EC%A0%84%EC%B2%98%EB%A6%AC-preprocessing\">tags: <code>전처리</code> <code>preprocessing</code> <a class=\"heading-anchor-permalink\" href=\"#tags%3A-%EC%A0%84%EC%B2%98%EB%A6%AC-preprocessing\">#</a></h6>\n<h4 id=\"1.-%EB%B6%88%EC%9A%A9%EC%96%B4-%EC%A0%9C%EA%B1%B0\">1. 불용어 제거 <a class=\"heading-anchor-permalink\" href=\"#1.-%EB%B6%88%EC%9A%A9%EC%96%B4-%EC%A0%9C%EA%B1%B0\">#</a></h4>\n<pre><code class=\"language-python\">def preprocessing( review, remove_stopwords = False ): \n    # 불용어 제거는 옵션으로 선택 가능하다.\n    \n    # 1. HTML 태그 제거\n    review_text = BeautifulSoup(review, &quot;html5lib&quot;).get_text()\t\n\n    # 2. 영어가 아닌 특수문자들을 공백(&quot; &quot;)으로 바꾸기\n    review_text = re.sub(&quot;[^a-zA-Z]&quot;, &quot; &quot;, review_text)\n\n    # 3. 대문자들을 소문자로 바꾸고 공백단위로 텍스트들 나눠서 리스트로 만든다.\n    words = review_text.lower().split()\n\n    if remove_stopwords: \n        # 4. 불용어들을 제거\n    \n        #영어에 관련된 불용어 불러오기\n        stops = set(stopwords.words(&quot;english&quot;))\n        # 불용어가 아닌 단어들로 이루어진 새로운 리스트 생성\n        words = [w for w in words if not w in stops]\n        # 5. 단어 리스트를 공백을 넣어서 하나의 글로 합친다.\t\n        clean_review = ' '.join(words)\n\n    else: # 불용어 제거하지 않을 때\n        clean_review = ' '.join(words)\n\n    return clean_review\n</code></pre>\n<h4 id=\"2.-%EB%8B%A8%EC%96%B4%EB%A5%BC-%EB%8B%A8%EC%96%B4%EC%82%AC%EC%A0%84%EC%9D%84-%EC%82%AC%EC%9A%A9%ED%95%B4%EC%84%9C-%EC%9D%B8%EB%8D%B1%EC%8A%A4%EB%A1%9C-%EB%B2%A1%ED%84%B0%ED%99%94\">2. 단어를 단어사전을 사용해서 인덱스로 벡터화 <a class=\"heading-anchor-permalink\" href=\"#2.-%EB%8B%A8%EC%96%B4%EB%A5%BC-%EB%8B%A8%EC%96%B4%EC%82%AC%EC%A0%84%EC%9D%84-%EC%82%AC%EC%9A%A9%ED%95%B4%EC%84%9C-%EC%9D%B8%EB%8D%B1%EC%8A%A4%EB%A1%9C-%EB%B2%A1%ED%84%B0%ED%99%94\">#</a></h4>\n<pre><code class=\"language-python\">tokenizer = Tokenizer()\ntokenizer.fit_on_texts(clean_train_reviews)\ntext_sequences = tokenizer.texts_to_sequences(clean_train_reviews)\n</code></pre>\n<h4 id=\"3.-%EB%AC%B8%EC%9E%A5-%EA%B8%B8%EC%9D%B4-%EB%8F%99%EA%B8%B0%ED%99%94\">3. 문장 길이 동기화 <a class=\"heading-anchor-permalink\" href=\"#3.-%EB%AC%B8%EC%9E%A5-%EA%B8%B8%EC%9D%B4-%EB%8F%99%EA%B8%B0%ED%99%94\">#</a></h4>\n<pre><code class=\"language-python\">word_vocab = tokenizer.word_index\nword_vocab[&quot;&lt;PAD&gt;&quot;] = 0\n\ndata_configs = {}\ndata_configs['vocab'] = word_vocab\ndata_configs['vocab_size'] = len(word_vocab)\n\nMAX_SEQUENCE_LENGTH = 174 \ntrain_inputs = pad_sequences(text_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n</code></pre>\n<ul>\n<li>Median 산출</li>\n<li>중간값에 맞추어 문장 길이 변환</li>\n<li>긴 문장은 후반부 생략</li>\n<li>짧은 문장은 패딩으로 채우기</li>\n</ul>\n<h4 id=\"4.-%EC%A0%84%EC%B2%98%EB%A6%AC-%ED%9B%84-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%80%EC%9E%A5\">4. 전처리 후 데이터 저장 <a class=\"heading-anchor-permalink\" href=\"#4.-%EC%A0%84%EC%B2%98%EB%A6%AC-%ED%9B%84-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%80%EC%9E%A5\">#</a></h4>\n<h4 id=\"%EB%B6%88%EC%9A%A9%EC%96%B4-%EC%A0%9C%EA%B1%B0%ED%95%B4%EC%84%9C-%ED%9E%88%EC%8A%A4%ED%86%A0%EA%B7%B8%EB%9E%A8-%EC%B0%8D%EC%96%B4%EB%B3%B4%EA%B8%B0\">불용어 제거해서 히스토그램 찍어보기 <a class=\"heading-anchor-permalink\" href=\"#%EB%B6%88%EC%9A%A9%EC%96%B4-%EC%A0%9C%EA%B1%B0%ED%95%B4%EC%84%9C-%ED%9E%88%EC%8A%A4%ED%86%A0%EA%B7%B8%EB%9E%A8-%EC%B0%8D%EC%96%B4%EB%B3%B4%EA%B8%B0\">#</a></h4>\n<pre><code class=\"language-python\">word_size = [len(r.split()) for r in clean_train_reviews]\nnp.median(word_size)\n\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(15,10))\nplt.hist(word_size, bins=50, facecolor='r', label='train')\n</code></pre>\n<p><img src=\"https://i.imgur.com/TIsvbgs.png\" alt=\"\"></p>\n<hr>\n<h6 id=\"tags%3A-%EB%AA%A8%EB%8D%B8%EB%A7%81-modeling\">tags: <code>모델링</code> <code>modeling</code> <a class=\"heading-anchor-permalink\" href=\"#tags%3A-%EB%AA%A8%EB%8D%B8%EB%A7%81-modeling\">#</a></h6>\n<p>word index ? tf-idf? 둘 중 뭐써야함?</p>\n<h3 id=\"tf-idf-vectorizer\">Tf-IDF Vectorizer <a class=\"heading-anchor-permalink\" href=\"#tf-idf-vectorizer\">#</a></h3>\n<p>:question: 왜 analyzer = 'char’로 주지…? 왜 'word’로 준거랑 차이가 없지…? SHIIITTT!!</p>\n<h4 id=\"test\">TEST <a class=\"heading-anchor-permalink\" href=\"#test\">#</a></h4>\n<ul>\n<li>analyzer=“char” &amp; ngram_range=(1,2): 0.782800</li>\n<li>analyzer=“char” &amp; ngram_range=(1,3): 0.859800</li>\n<li>analyzer=“char” &amp; ngram_range=(1,7): 0.850800</li>\n<li>analyzer=“word” &amp; ngram_range=(1,2): 0.887600</li>\n</ul>\n<p><code>vectorizer = TfidfVectorizer(min_df = 0.0, analyzer=&quot;char&quot;, sublinear_tf=True, ngram_range=(1,3), max_features=5000)</code></p>\n<p>TfidfVectorizer 파라미터 정리</p>\n<ul>\n<li>min-df : 설정한 값 이상 등장하는 단어만 등록, 단어의 등장횟수가 아니라 문서의 수</li>\n<li>analyzer : 단어 단위로 볼지 문장 단위로 볼지</li>\n<li>ngram_range : 문자 혹은 단어의 묶음을 처리하는 범위, 단어를 기준으로 하고 (1, 1)로 놓았을 경우 벡터라이저와 같은 결과를 보임(단어 하나씩만 처리하기 때문) (1,2)로 놓았을 경우 go, go to 등이 개별 단어로 처리된다. 묶여야 의미가 살아나는 표현들을 처리하기 위한 파리미터</li>\n<li>max_feature : 각 벡터의 최대 길이를 처리</li>\n<li>sublinear_tf : 단어의 빈도 수에 대한 스무딩 여부, 로그값으로 변환해 값을 완만하게 처리</li>\n</ul>\n<pre><code class=\"language-python\">import numpy as np \ndef sublinear_func(input): \n    result = 1 + np.log(input) \n    return result\n</code></pre>\n",
      "id": 3
    },
    {
      "path": "1-Machine Learning/4-Categorizer.md",
      "url": "1-Machine Learning/4-Categorizer.html",
      "content": "2021-02-09\n===\n###### tags: `Embedding` `Categorizing`\n\n### Gensim Word2Vec\n? word2vec이면 `cbow` or  `skip-gram`일텐데 둘 중 뭘로 하려나?\n\nword2vec의 패러미터에 따라 모드를 선택할 수 있음. 1: skip-gram; otherwise CBOW [document](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec)\n\n? Word2Vec Downsampling은 어떻게 이루어지나\n0.001일 경우 1000번 나오는걸 한번만 학습? 1000번 이상 나오면 그이후로는 학습을 하지 않는다?\n얼마나 자주 나온 단어를, 얼만큼 샘플링하여 학습하는거징?\n\n### RandomForest\nn개의 의사결정 트리를 통해 문장을 분류하는 기법\n패러미터\n* n_estimators: 몇 개의 트리를 만들 것인지. 나중에 이 트리들의 결과값을 앙상블하여 최종 결과를 만듬\n* max_depth: 각 tree의 최대 깊이. 디폴트일 경우 각 leaf가 pure하거나 min_samples_split개보다 적게 가지고 있을 때까지 확장됨.\n* max_samples: train데이터에서 학습에 사용할 샘플 데이터 갯수\n\n### Vectorizer\n* CountVectorizer: word index에서 각 단어별 빈도 수를 count\n* TfIdf: 문장에서 단어의 중요도를 기반\n* Word2Vec: CBow / Skip-Gram 알고리즘으로 단어끼리 유사도를 기반\n\n### Categorizer\n* Linear Regression\n* Random Forest\n* KNN\n* K-Means",
      "html": "<h1 id=\"2021-02-09\">2021-02-09 <a class=\"heading-anchor-permalink\" href=\"#2021-02-09\">#</a></h1>\n<h6 id=\"tags%3A-embedding-categorizing\">tags: <code>Embedding</code> <code>Categorizing</code> <a class=\"heading-anchor-permalink\" href=\"#tags%3A-embedding-categorizing\">#</a></h6>\n<h3 id=\"gensim-word2vec\">Gensim Word2Vec <a class=\"heading-anchor-permalink\" href=\"#gensim-word2vec\">#</a></h3>\n<p>? word2vec이면 <code>cbow</code> or  <code>skip-gram</code>일텐데 둘 중 뭘로 하려나?</p>\n<p>word2vec의 패러미터에 따라 모드를 선택할 수 있음. 1: skip-gram; otherwise CBOW <a href=\"https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec\">document</a></p>\n<p>? Word2Vec Downsampling은 어떻게 이루어지나\n0.001일 경우 1000번 나오는걸 한번만 학습? 1000번 이상 나오면 그이후로는 학습을 하지 않는다?\n얼마나 자주 나온 단어를, 얼만큼 샘플링하여 학습하는거징?</p>\n<h3 id=\"randomforest\">RandomForest <a class=\"heading-anchor-permalink\" href=\"#randomforest\">#</a></h3>\n<p>n개의 의사결정 트리를 통해 문장을 분류하는 기법\n패러미터</p>\n<ul>\n<li>n_estimators: 몇 개의 트리를 만들 것인지. 나중에 이 트리들의 결과값을 앙상블하여 최종 결과를 만듬</li>\n<li>max_depth: 각 tree의 최대 깊이. 디폴트일 경우 각 leaf가 pure하거나 min_samples_split개보다 적게 가지고 있을 때까지 확장됨.</li>\n<li>max_samples: train데이터에서 학습에 사용할 샘플 데이터 갯수</li>\n</ul>\n<h3 id=\"vectorizer\">Vectorizer <a class=\"heading-anchor-permalink\" href=\"#vectorizer\">#</a></h3>\n<ul>\n<li>CountVectorizer: word index에서 각 단어별 빈도 수를 count</li>\n<li>TfIdf: 문장에서 단어의 중요도를 기반</li>\n<li>Word2Vec: CBow / Skip-Gram 알고리즘으로 단어끼리 유사도를 기반</li>\n</ul>\n<h3 id=\"categorizer\">Categorizer <a class=\"heading-anchor-permalink\" href=\"#categorizer\">#</a></h3>\n<ul>\n<li>Linear Regression</li>\n<li>Random Forest</li>\n<li>KNN</li>\n<li>K-Means</li>\n</ul>\n",
      "id": 4
    },
    {
      "path": "1-Machine Learning/5-LSTM RNN CNN.md",
      "url": "1-Machine Learning/5-LSTM RNN CNN.html",
      "content": "2021-02-16\n===\n\n###### tags: `RNN` `LSTM` `CNN`\n\nhttps://mingrammer.com/understanding-the-asterisk-of-python/\n\nLSTM의 output은 hidden state과 같은거?\nRNN의 output은 hidden state과 다른거?\n### RNN\n\n![](https://i.imgur.com/go68Xut.png)\n**노드 =  메모리 셀 = RNN 셀** :  은닉층에서 활성화 함수를 통해 결과를 내보내는 역할을 하는 노드\n 바로 이전 시점에서의 은닉층의 메모리 셀에서 나온 값을 자신의 입력으로 사용\n**은닉 상태(hidden state)** : 메모리 셀이 출력층 방향으로 또는 다음 시점 t+1의 자신에게 보내는 값\n\n![](https://i.imgur.com/Gn6inQ6.png =200x)\n\n**Wx** : 입력층에서 입력값을 위한 가중치\n**Wh**  : 이전 시점 t-1의 은닉 상태값인 ht−1을 위한 가중치 \n은닉층 : ht=tanh(Wxxt+Whht−1+b)\n출력층 : yt=f(Wyht+b)\n\n![](https://i.imgur.com/FTwMYxE.png)\n\n**각각의 가중치 Wx, Wh, Wy의 값은 모든 시점에서 값을 동일하게 공유**\n\n출처 : https://wikidocs.net/22886\n\n\n### LSTM vs RNN\nRNN은 초기에 들어온 information이 문장이 길어질수록 vanish되는 현상이 있다.\nLSTM은 Cell state 사용하여 위 현상을 막아준다.\n\nhidden state값을 그대로 output으로 사용할 수도 있지만 hidden에 별도 공식을 추가하여 output으로 사용을 할 수도 있다.\n\n### CNN\nYoon Kim(2014) http://emnlp2014.org/papers/pdf/EMNLP2014181.pdf\n- CNN 레이어 1개만 사용해도 괜찮은 성능을 보여줌\n- 모델 모형 참조",
      "html": "<h1 id=\"2021-02-16\">2021-02-16 <a class=\"heading-anchor-permalink\" href=\"#2021-02-16\">#</a></h1>\n<h6 id=\"tags%3A-rnn-lstm-cnn\">tags: <code>RNN</code> <code>LSTM</code> <code>CNN</code> <a class=\"heading-anchor-permalink\" href=\"#tags%3A-rnn-lstm-cnn\">#</a></h6>\n<p><a href=\"https://mingrammer.com/understanding-the-asterisk-of-python/\">https://mingrammer.com/understanding-the-asterisk-of-python/</a></p>\n<p>LSTM의 output은 hidden state과 같은거?\nRNN의 output은 hidden state과 다른거?</p>\n<h3 id=\"rnn\">RNN <a class=\"heading-anchor-permalink\" href=\"#rnn\">#</a></h3>\n<p><img src=\"https://i.imgur.com/go68Xut.png\" alt=\"\">\n<strong>노드 =  메모리 셀 = RNN 셀</strong> :  은닉층에서 활성화 함수를 통해 결과를 내보내는 역할을 하는 노드\n바로 이전 시점에서의 은닉층의 메모리 셀에서 나온 값을 자신의 입력으로 사용\n<strong>은닉 상태(hidden state)</strong> : 메모리 셀이 출력층 방향으로 또는 다음 시점 t+1의 자신에게 보내는 값</p>\n<p>![](<a href=\"https://i.imgur.com/Gn6inQ6.png\">https://i.imgur.com/Gn6inQ6.png</a> =200x)</p>\n<p><strong>Wx</strong> : 입력층에서 입력값을 위한 가중치\n<strong>Wh</strong>  : 이전 시점 t-1의 은닉 상태값인 ht−1을 위한 가중치\n은닉층 : ht=tanh(Wxxt+Whht−1+b)\n출력층 : yt=f(Wyht+b)</p>\n<p><img src=\"https://i.imgur.com/FTwMYxE.png\" alt=\"\"></p>\n<p><strong>각각의 가중치 Wx, Wh, Wy의 값은 모든 시점에서 값을 동일하게 공유</strong></p>\n<p>출처 : <a href=\"https://wikidocs.net/22886\">https://wikidocs.net/22886</a></p>\n<h3 id=\"lstm-vs-rnn\">LSTM vs RNN <a class=\"heading-anchor-permalink\" href=\"#lstm-vs-rnn\">#</a></h3>\n<p>RNN은 초기에 들어온 information이 문장이 길어질수록 vanish되는 현상이 있다.\nLSTM은 Cell state 사용하여 위 현상을 막아준다.</p>\n<p>hidden state값을 그대로 output으로 사용할 수도 있지만 hidden에 별도 공식을 추가하여 output으로 사용을 할 수도 있다.</p>\n<h3 id=\"cnn\">CNN <a class=\"heading-anchor-permalink\" href=\"#cnn\">#</a></h3>\n<p>Yoon Kim(2014) <a href=\"http://emnlp2014.org/papers/pdf/EMNLP2014181.pdf\">http://emnlp2014.org/papers/pdf/EMNLP2014181.pdf</a></p>\n<ul>\n<li>CNN 레이어 1개만 사용해도 괜찮은 성능을 보여줌</li>\n<li>모델 모형 참조</li>\n</ul>\n",
      "id": 5
    },
    {
      "path": "1-Machine Learning/6-Sentiment Modeling.md",
      "url": "1-Machine Learning/6-Sentiment Modeling.html",
      "content": "2021-02-23\n===\n\n###### tags: `preprocessing` `한글`\n\n- 한글 형태소 분석기\nKomoran 추천추천 강추천\n\n- 임의 텍스트를 sequence 벡터로 표현\n```python\n!pip install konlpy\n\nfrom keras.preprocessing.text import text_to_word_sequence\nfrom konlpy.tag import Okt\nimport json\nimport re\n\ndef preprocessing(review):\n    okt = Okt()\n    stop_words = set(['은', '는', '이', '가', '하', '아', '것', '들','의', '있', '되', '수', '보', '주', '등', '한'])\n    \n    review_text = re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]\", \"\", review)\n    word_review = okt.morphs(review_text, stem=True)\n    word_review = [token for token in word_review if not token in stop_words]    \n    return word_review\n\ndef to_sequence(text, word_index):\n    tokens = preprocessing(text)\n    print(tokens)\n    return [word_index.get(w) for w in tokens if w in word_index]\n\n\n\nwith open('/content/drive/MyDrive/SKT/Machine Learning Learning/data_in_4.2.2/data_configs.json') as json_file:\n    json_data = json.load(json_file)\n    word_index = json_data['vocab']\n    print(json_data['vocab'])\n\n    sequence = to_sequence('영화를 겁나 재밌게 봤어요', word_index)\n    print(sequence)\n\n```\n\n- Sequence를 Model로 predict\n```python\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\ninput = '영화 겁나 재미없다'\nprint('input: ' + input)\nsequence = to_sequence(input, word_index)\nsequence = [sequence]\nmodel.predict(pad_sequences(sequence, 8))\n```\n\n- Result\n```\ninput: 영화 겁나 재미없다\n['영화', '겁나다', '재미없다']\narray([[0.00208169]], dtype=float32)\n\n0.00208169 -> 0(부정)과 가까운 값\n```\n```\ninput: 영화 겁나 재밌다\n['영화', '겁나다', '재밌다']\narray([[0.99173295]], dtype=float32)\n\n0.99173295 -> 1(긍정)과 가까운 값\n```",
      "html": "<h1 id=\"2021-02-23\">2021-02-23 <a class=\"heading-anchor-permalink\" href=\"#2021-02-23\">#</a></h1>\n<h6 id=\"tags%3A-preprocessing-%ED%95%9C%EA%B8%80\">tags: <code>preprocessing</code> <code>한글</code> <a class=\"heading-anchor-permalink\" href=\"#tags%3A-preprocessing-%ED%95%9C%EA%B8%80\">#</a></h6>\n<ul>\n<li>\n<p>한글 형태소 분석기\nKomoran 추천추천 강추천</p>\n</li>\n<li>\n<p>임의 텍스트를 sequence 벡터로 표현</p>\n</li>\n</ul>\n<pre><code class=\"language-python\">!pip install konlpy\n\nfrom keras.preprocessing.text import text_to_word_sequence\nfrom konlpy.tag import Okt\nimport json\nimport re\n\ndef preprocessing(review):\n    okt = Okt()\n    stop_words = set(['은', '는', '이', '가', '하', '아', '것', '들','의', '있', '되', '수', '보', '주', '등', '한'])\n    \n    review_text = re.sub(&quot;[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]&quot;, &quot;&quot;, review)\n    word_review = okt.morphs(review_text, stem=True)\n    word_review = [token for token in word_review if not token in stop_words]    \n    return word_review\n\ndef to_sequence(text, word_index):\n    tokens = preprocessing(text)\n    print(tokens)\n    return [word_index.get(w) for w in tokens if w in word_index]\n\n\n\nwith open('/content/drive/MyDrive/SKT/Machine Learning Learning/data_in_4.2.2/data_configs.json') as json_file:\n    json_data = json.load(json_file)\n    word_index = json_data['vocab']\n    print(json_data['vocab'])\n\n    sequence = to_sequence('영화를 겁나 재밌게 봤어요', word_index)\n    print(sequence)\n\n</code></pre>\n<ul>\n<li>Sequence를 Model로 predict</li>\n</ul>\n<pre><code class=\"language-python\">from tensorflow.keras.preprocessing.sequence import pad_sequences\ninput = '영화 겁나 재미없다'\nprint('input: ' + input)\nsequence = to_sequence(input, word_index)\nsequence = [sequence]\nmodel.predict(pad_sequences(sequence, 8))\n</code></pre>\n<ul>\n<li>Result</li>\n</ul>\n<pre><code>input: 영화 겁나 재미없다\n['영화', '겁나다', '재미없다']\narray([[0.00208169]], dtype=float32)\n\n0.00208169 -&gt; 0(부정)과 가까운 값\n</code></pre>\n<pre><code>input: 영화 겁나 재밌다\n['영화', '겁나다', '재밌다']\narray([[0.99173295]], dtype=float32)\n\n0.99173295 -&gt; 1(긍정)과 가까운 값\n</code></pre>\n",
      "id": 6
    },
    {
      "path": "1-Machine Learning/7-Bagging and Boosting.md",
      "url": "1-Machine Learning/7-Bagging and Boosting.html",
      "content": "2021-03-02\n===\n\n###### tags: `유사도` `XG Boost` `Bagging`\n- 중복 문항 체크\n    - pd Series의 value_counts 함수\n    ```python=\n    temp_array = pd.Series([1, 1, 1, 2, 3, 4, 5])\n    temp_array.value_counts()\n    ```\n    - result\n    ```\n    1    3\n    5    1\n    4    1\n    3    1\n    2    1\n    ```\n    \n- Preprocessing\n    - Box plot으로 데이터의 분포를 확인\n    - Bar chart로 라벨 별 데이터 개수가 균등한지 확인\n        - 라벨 별 데이터 균등하게 맞추기\n        ```python=\n        train_pos_data = train_data.loc[train_data['is_duplicate'] == 1]\n        train_neg_data = train_data.loc[train_data['is_duplicate'] == 0]\n\n        class_difference = len(train_neg_data) - len(train_pos_data)\n        sample_frac = 1 - (class_difference / len(train_neg_data))\n\n        train_neg_data = train_neg_data.sample(frac = sample_frac)\n        ```\n    - Character와 Word 단위로 문항을 나눠 그 길이로 box plot과 bar chart를 확인하는 행위는 무엇을 위함인가..?\n    - 데이터의 보편적인 특징(물음표로 끝난다거나 대문자로 시작하는 것)은 데이터 전처리에서 제거하여 편향된 학습을 방지\n\n\n- XG Boost (Tree Boosting)\n    - 앙상블이란 여러개의 학습 알고리즘을 사용해 더 좋은 성능을 얻음\n    - 앙상블에는 배깅과 부스팅이 존재\n        - Bagging: 여러개의 학습 알고리즘, 모델을 통해 각각 결과를 예측 후 모든 결과를 동등하게 취합하여 최종 결과를 얻음\n            ex: Random Forest\n        - Boosting: 여러개의 학습 알고리즘, 모델의 결과를 순차적으로 취합, 잘못 예측한 부분에 가중치를 주어 재학습 진행\n    - 여러개의 의사결정 트리를 사용하되 결과들의 평균을 사용하는게 아니라 오답에 대한 가중치를 주어 재학습 진행\n\n\n    ```python=\n    train_data = xgb.DMatrix(train_input.sum(axis=1), label=train_label) # 학습 데이터 읽어 오기\n    eval_data = xgb.DMatrix(eval_input.sum(axis=1), label=eval_label) # 평가 데이터 읽어 오기\n\n    data_list = [(train_data, 'train'), (eval_data, 'valid')]\n    \n    params = {} # 인자를 통해 XGB모델에 넣어 주자 \n    params['objective'] = 'binary:logistic' # 로지스틱 예측을 통해서 \n    params['eval_metric'] = 'rmse' # root mean square error를 사용  \n\n    bst = xgb.train(params, train_data, num_boost_round = 1000, evals = data_list, early_stopping_rounds=10)\n    ``` \n    \n    - Bagging은 Train Data Set을 n개로 나누어 n개의 트리(모델)에 각각 학습을 시킨 후\n      Evaluate Data Set으로 n개의 모델을 평가하는데 그 중 가장 평가 결과가 우수한 트리(모델)의 결과를 최종 결과로 사용\n    - XG Boosting은 Train Data Set을 n개의 트리(모델)에 학습 시킨 후\n      Evaluate Data Set으로 n개의 모델을 평가하는데 평가 과정 중 오답인 데이터를 Train Data Set에 포함되도록 중요도를 조절하여 다음 학습 차례 때 해당 오답처리 되었던 데이터에 대해 정답이 될 수 있도록 학습을 진행",
      "html": "<h1 id=\"2021-03-02\">2021-03-02 <a class=\"heading-anchor-permalink\" href=\"#2021-03-02\">#</a></h1>\n<h6 id=\"tags%3A-%EC%9C%A0%EC%82%AC%EB%8F%84-xg-boost-bagging\">tags: <code>유사도</code> <code>XG Boost</code> <code>Bagging</code> <a class=\"heading-anchor-permalink\" href=\"#tags%3A-%EC%9C%A0%EC%82%AC%EB%8F%84-xg-boost-bagging\">#</a></h6>\n<ul>\n<li>\n<p>중복 문항 체크</p>\n<ul>\n<li>pd Series의 value_counts 함수</li>\n</ul>\n<pre><code class=\"language-python=\">temp_array = pd.Series([1, 1, 1, 2, 3, 4, 5])\ntemp_array.value_counts()\n</code></pre>\n<ul>\n<li>result</li>\n</ul>\n<pre><code>1    3\n5    1\n4    1\n3    1\n2    1\n</code></pre>\n</li>\n<li>\n<p>Preprocessing</p>\n<ul>\n<li>Box plot으로 데이터의 분포를 확인</li>\n<li>Bar chart로 라벨 별 데이터 개수가 균등한지 확인\n<ul>\n<li>라벨 별 데이터 균등하게 맞추기</li>\n</ul>\n<pre><code class=\"language-python=\">train_pos_data = train_data.loc[train_data['is_duplicate'] == 1]\ntrain_neg_data = train_data.loc[train_data['is_duplicate'] == 0]\n\nclass_difference = len(train_neg_data) - len(train_pos_data)\nsample_frac = 1 - (class_difference / len(train_neg_data))\n\ntrain_neg_data = train_neg_data.sample(frac = sample_frac)\n</code></pre>\n</li>\n<li>Character와 Word 단위로 문항을 나눠 그 길이로 box plot과 bar chart를 확인하는 행위는 무엇을 위함인가…?</li>\n<li>데이터의 보편적인 특징(물음표로 끝난다거나 대문자로 시작하는 것)은 데이터 전처리에서 제거하여 편향된 학습을 방지</li>\n</ul>\n</li>\n<li>\n<p>XG Boost (Tree Boosting)</p>\n<ul>\n<li>앙상블이란 여러개의 학습 알고리즘을 사용해 더 좋은 성능을 얻음</li>\n<li>앙상블에는 배깅과 부스팅이 존재\n<ul>\n<li>Bagging: 여러개의 학습 알고리즘, 모델을 통해 각각 결과를 예측 후 모든 결과를 동등하게 취합하여 최종 결과를 얻음\nex: Random Forest</li>\n<li>Boosting: 여러개의 학습 알고리즘, 모델의 결과를 순차적으로 취합, 잘못 예측한 부분에 가중치를 주어 재학습 진행</li>\n</ul>\n</li>\n<li>여러개의 의사결정 트리를 사용하되 결과들의 평균을 사용하는게 아니라 오답에 대한 가중치를 주어 재학습 진행</li>\n</ul>\n<pre><code class=\"language-python=\">train_data = xgb.DMatrix(train_input.sum(axis=1), label=train_label) # 학습 데이터 읽어 오기\neval_data = xgb.DMatrix(eval_input.sum(axis=1), label=eval_label) # 평가 데이터 읽어 오기\n\ndata_list = [(train_data, 'train'), (eval_data, 'valid')]\n\nparams = {} # 인자를 통해 XGB모델에 넣어 주자 \nparams['objective'] = 'binary:logistic' # 로지스틱 예측을 통해서 \nparams['eval_metric'] = 'rmse' # root mean square error를 사용  \n\nbst = xgb.train(params, train_data, num_boost_round = 1000, evals = data_list, early_stopping_rounds=10)\n</code></pre>\n<ul>\n<li>Bagging은 Train Data Set을 n개로 나누어 n개의 트리(모델)에 각각 학습을 시킨 후\nEvaluate Data Set으로 n개의 모델을 평가하는데 그 중 가장 평가 결과가 우수한 트리(모델)의 결과를 최종 결과로 사용</li>\n<li>XG Boosting은 Train Data Set을 n개의 트리(모델)에 학습 시킨 후\nEvaluate Data Set으로 n개의 모델을 평가하는데 평가 과정 중 오답인 데이터를 Train Data Set에 포함되도록 중요도를 조절하여 다음 학습 차례 때 해당 오답처리 되었던 데이터에 대해 정답이 될 수 있도록 학습을 진행</li>\n</ul>\n</li>\n</ul>\n",
      "id": 7
    },
    {
      "path": "1-Machine Learning/8-Chatbot.md",
      "url": "1-Machine Learning/8-Chatbot.html",
      "content": "2021-03-16\n===\n\n###### tags: `Chatbot`\n\n- 형태소 분석기를 이용한 품사 분석 전처리\n```python=\nquery_NVA_token_sentences = list()\nanswer_NVA_token_sentences = list()\n\nfor s in query_sentences:\n    for token, tag in okt.pos(s.replace(' ', '')):\n        if tag == 'Noun' or tag == 'Verb' or tag == 'Adjective':\n            query_NVA_token_sentences.append(token)\n\nfor s in answer_sentences:\n    for token, tag in okt.pos(s.replace(' ', '')):\n        if tag == 'Noun' or tag == 'Verb' or tag == 'Adjective':\n            answer_NVA_token_sentences.append(token)\n            \nquery_NVA_token_sentences = ' '.join(query_NVA_token_sentences)\nanswer_NVA_token_sentences = ' '.join(answer_NVA_token_sentences)\n```\n\n- idx2char와 char2idx 딕셔너리 생성방법\n```python=\ndef make_vocabulary(vocabulary_list):\n    # 리스트를 키가 단어이고 값이 인덱스인 딕셔너리를 만든다.\n    char2idx = {char: idx for idx, char in enumerate(vocabulary_list)}\n    # 리스트를 키가 인덱스이고 값이 단어인 딕셔너리를 만든다.\n    idx2char = {idx: char for idx, char in enumerate(vocabulary_list)}\n    return char2idx, idx2char\n```\n\n- encoder processing\n```python=\ndef enc_processing(value, dictionary, tokenize_as_morph=False):\n    sequences_input_index = []\n    sequences_length = []\n    if tokenize_as_morph:\n        value = prepro_like_morphlized(value)\n\n    # 한줄씩 불어온다.\n    for sequence in value:\n        # FILTERS = \"([~.,!?\\\"':;)(])\"\n        sequence = re.sub(CHANGE_FILTER, \"\", sequence)\n        sequence_index = []\n        # 문장을 스페이스 단위로 자르고 있다.\n        for word in sequence.split():\n            # 잘려진 단어들이 딕셔너리에 존재 하는지 보고 그 값을 가져와 sequence_index에 추가한다.\n            if dictionary.get(word) is not None:\n                sequence_index.extend([dictionary[word]])\n            # 잘려진 단어가 딕셔너리에 존재 하지 않는 경우 이므로 UNK(2)를 넣어 준다.\n            else:\n                sequence_index.extend([dictionary[UNK]])\n        # 문장 제한 길이보다 길어질 경우 뒤에 토큰을 자르고 있다.\n        if len(sequence_index) > MAX_SEQUENCE:\n            sequence_index = sequence_index[:MAX_SEQUENCE]\n        # max_sequence_length보다 문장 길이가\n        # 작다면 빈 부분에 PAD(0)를 넣어준다.\n        sequence_index += (MAX_SEQUENCE - len(sequence_index)) * [dictionary[PAD]]\n        # 인덱스화 되어 있는 값을\n        # sequences_input_index에 넣어 준다.\n        sequences_input_index.append(sequence_index)\n    return np.asarray(sequences_input_index)\n```\n\n- decoder processing\n    - 디코더 입력값: `<SOS>, 그래, 오랜만이야, <PAD>`\n    - 디코더 타깃값: `그래, 오랜만이야, <END>, <PAD>`\n    \n- encodeer\n```python=\nclass Encoder(tf.keras.layers.Layer):\ndef __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n    super(Encoder, self).__init__()\n    self.batch_sz = batch_sz\n    self.enc_units = enc_units\n    self.vocab_size = vocab_size \n    self.embedding_dim = embedding_dim          \n\n    self.embedding = tf.keras.layers.Embedding(self.vocab_size, self.embedding_dim)\n    self.gru = tf.keras.layers.GRU(self.enc_units,\n                                   return_sequences=True,\n                                   return_state=True,\n                                   recurrent_initializer='glorot_uniform')\n\ndef call(self, x, hidden):\n    x = self.embedding(x)\n    output, state = self.gru(x, initial_state = hidden)\n    return output, state\n\ndef initialize_hidden_state(self, inp):\n    return tf.zeros((tf.shape(inp)[0], self.enc_units))\n```\n\n- decoder\n```python=\nclass Decoder(tf.keras.layers.Layer):\n    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n        super(Decoder, self).__init__()\n        \n        self.batch_sz = batch_sz\n        self.dec_units = dec_units\n        self.vocab_size = vocab_size \n        self.embedding_dim = embedding_dim  \n        \n        self.embedding = tf.keras.layers.Embedding(self.vocab_size, self.embedding_dim)\n        self.gru = tf.keras.layers.GRU(self.dec_units,\n                                       return_sequences=True,\n                                       return_state=True,\n                                       recurrent_initializer='glorot_uniform')\n        self.fc = tf.keras.layers.Dense(self.vocab_size)\n\n        self.attention = BahdanauAttention(self.dec_units)\n        \n    def call(self, x, hidden, enc_output):\n        context_vector, attention_weights = self.attention(hidden, enc_output)\n\n        x = self.embedding(x)\n\n        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n\n        output, state = self.gru(x)\n        output = tf.reshape(output, (-1, output.shape[2]))\n            \n        x = self.fc(output)\n        \n        return x, state, attention_weights\n```\n\n- attention\n```python=\nclass BahdanauAttention(tf.keras.layers.Layer):\n    def __init__(self, units):\n        super(BahdanauAttention, self).__init__()\n        self.W1 = tf.keras.layers.Dense(units)\n        self.W2 = tf.keras.layers.Dense(units)\n        self.V = tf.keras.layers.Dense(1)\n\n    def call(self, query, values):\n        hidden_with_time_axis = tf.expand_dims(query, 1)\n\n        print(values)\n        score = self.V(tf.nn.tanh(\n            self.W1(values) + self.W2(hidden_with_time_axis)))\n\n        attention_weights = tf.nn.softmax(score, axis=1)\n\n        context_vector = attention_weights * values\n        context_vector = tf.reduce_sum(context_vector, axis=1)\n\n        return context_vector, attention_weights\n```\n- seq2seq\n```python=\nclass seq2seq(tf.keras.Model):\n    def __init__(self, vocab_size, embedding_dim, enc_units, dec_units, batch_sz, end_token_idx=2):    \n        super(seq2seq, self).__init__()\n        self.end_token_idx = end_token_idx\n        self.encoder = Encoder(vocab_size, embedding_dim, enc_units, batch_sz) \n        self.decoder = Decoder(vocab_size, embedding_dim, dec_units, batch_sz) \n\n    def call(self, x):\n        inp, tar = x\n        \n        enc_hidden = self.encoder.initialize_hidden_state(inp)\n        enc_output, enc_hidden = self.encoder(inp, enc_hidden)\n\n        dec_hidden = enc_hidden\n\n        predict_tokens = list()\n        for t in range(0, tar.shape[1]):\n            dec_input = tf.dtypes.cast(tf.expand_dims(tar[:, t], 1), tf.float32) \n            predictions, dec_hidden, _ = self.decoder(dec_input, dec_hidden, enc_output)\n            predict_tokens.append(tf.dtypes.cast(predictions, tf.float32))   \n        return tf.stack(predict_tokens, axis=1)\n    \n    def inference(self, x):\n        inp  = x\n\n        enc_hidden = self.encoder.initialize_hidden_state(inp)\n        enc_output, enc_hidden = self.encoder(inp, enc_hidden)\n\n        dec_hidden = enc_hidden\n        \n        dec_input = tf.expand_dims([char2idx[std_index]], 1)\n        \n        predict_tokens = list()\n        for t in range(0, MAX_SEQUENCE):\n            predictions, dec_hidden, _ = self.decoder(dec_input, dec_hidden, enc_output)\n            predict_token = tf.argmax(predictions[0])\n            \n            if predict_token == self.end_token_idx:\n                break\n            \n            predict_tokens.append(predict_token)\n            dec_input = tf.dtypes.cast(tf.expand_dims([predict_token], 0), tf.float32)   \n            \n        return tf.stack(predict_tokens, axis=0).numpy()\n```\n",
      "html": "<h1 id=\"2021-03-16\">2021-03-16 <a class=\"heading-anchor-permalink\" href=\"#2021-03-16\">#</a></h1>\n<h6 id=\"tags%3A-chatbot\">tags: <code>Chatbot</code> <a class=\"heading-anchor-permalink\" href=\"#tags%3A-chatbot\">#</a></h6>\n<ul>\n<li>형태소 분석기를 이용한 품사 분석 전처리</li>\n</ul>\n<pre><code class=\"language-python=\">query_NVA_token_sentences = list()\nanswer_NVA_token_sentences = list()\n\nfor s in query_sentences:\n    for token, tag in okt.pos(s.replace(' ', '')):\n        if tag == 'Noun' or tag == 'Verb' or tag == 'Adjective':\n            query_NVA_token_sentences.append(token)\n\nfor s in answer_sentences:\n    for token, tag in okt.pos(s.replace(' ', '')):\n        if tag == 'Noun' or tag == 'Verb' or tag == 'Adjective':\n            answer_NVA_token_sentences.append(token)\n            \nquery_NVA_token_sentences = ' '.join(query_NVA_token_sentences)\nanswer_NVA_token_sentences = ' '.join(answer_NVA_token_sentences)\n</code></pre>\n<ul>\n<li>idx2char와 char2idx 딕셔너리 생성방법</li>\n</ul>\n<pre><code class=\"language-python=\">def make_vocabulary(vocabulary_list):\n    # 리스트를 키가 단어이고 값이 인덱스인 딕셔너리를 만든다.\n    char2idx = {char: idx for idx, char in enumerate(vocabulary_list)}\n    # 리스트를 키가 인덱스이고 값이 단어인 딕셔너리를 만든다.\n    idx2char = {idx: char for idx, char in enumerate(vocabulary_list)}\n    return char2idx, idx2char\n</code></pre>\n<ul>\n<li>encoder processing</li>\n</ul>\n<pre><code class=\"language-python=\">def enc_processing(value, dictionary, tokenize_as_morph=False):\n    sequences_input_index = []\n    sequences_length = []\n    if tokenize_as_morph:\n        value = prepro_like_morphlized(value)\n\n    # 한줄씩 불어온다.\n    for sequence in value:\n        # FILTERS = &quot;([~.,!?\\&quot;':;)(])&quot;\n        sequence = re.sub(CHANGE_FILTER, &quot;&quot;, sequence)\n        sequence_index = []\n        # 문장을 스페이스 단위로 자르고 있다.\n        for word in sequence.split():\n            # 잘려진 단어들이 딕셔너리에 존재 하는지 보고 그 값을 가져와 sequence_index에 추가한다.\n            if dictionary.get(word) is not None:\n                sequence_index.extend([dictionary[word]])\n            # 잘려진 단어가 딕셔너리에 존재 하지 않는 경우 이므로 UNK(2)를 넣어 준다.\n            else:\n                sequence_index.extend([dictionary[UNK]])\n        # 문장 제한 길이보다 길어질 경우 뒤에 토큰을 자르고 있다.\n        if len(sequence_index) &gt; MAX_SEQUENCE:\n            sequence_index = sequence_index[:MAX_SEQUENCE]\n        # max_sequence_length보다 문장 길이가\n        # 작다면 빈 부분에 PAD(0)를 넣어준다.\n        sequence_index += (MAX_SEQUENCE - len(sequence_index)) * [dictionary[PAD]]\n        # 인덱스화 되어 있는 값을\n        # sequences_input_index에 넣어 준다.\n        sequences_input_index.append(sequence_index)\n    return np.asarray(sequences_input_index)\n</code></pre>\n<ul>\n<li>\n<p>decoder processing</p>\n<ul>\n<li>디코더 입력값: <code>&lt;SOS&gt;, 그래, 오랜만이야, &lt;PAD&gt;</code></li>\n<li>디코더 타깃값: <code>그래, 오랜만이야, &lt;END&gt;, &lt;PAD&gt;</code></li>\n</ul>\n</li>\n<li>\n<p>encodeer</p>\n</li>\n</ul>\n<pre><code class=\"language-python=\">class Encoder(tf.keras.layers.Layer):\ndef __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n    super(Encoder, self).__init__()\n    self.batch_sz = batch_sz\n    self.enc_units = enc_units\n    self.vocab_size = vocab_size \n    self.embedding_dim = embedding_dim          \n\n    self.embedding = tf.keras.layers.Embedding(self.vocab_size, self.embedding_dim)\n    self.gru = tf.keras.layers.GRU(self.enc_units,\n                                   return_sequences=True,\n                                   return_state=True,\n                                   recurrent_initializer='glorot_uniform')\n\ndef call(self, x, hidden):\n    x = self.embedding(x)\n    output, state = self.gru(x, initial_state = hidden)\n    return output, state\n\ndef initialize_hidden_state(self, inp):\n    return tf.zeros((tf.shape(inp)[0], self.enc_units))\n</code></pre>\n<ul>\n<li>decoder</li>\n</ul>\n<pre><code class=\"language-python=\">class Decoder(tf.keras.layers.Layer):\n    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n        super(Decoder, self).__init__()\n        \n        self.batch_sz = batch_sz\n        self.dec_units = dec_units\n        self.vocab_size = vocab_size \n        self.embedding_dim = embedding_dim  \n        \n        self.embedding = tf.keras.layers.Embedding(self.vocab_size, self.embedding_dim)\n        self.gru = tf.keras.layers.GRU(self.dec_units,\n                                       return_sequences=True,\n                                       return_state=True,\n                                       recurrent_initializer='glorot_uniform')\n        self.fc = tf.keras.layers.Dense(self.vocab_size)\n\n        self.attention = BahdanauAttention(self.dec_units)\n        \n    def call(self, x, hidden, enc_output):\n        context_vector, attention_weights = self.attention(hidden, enc_output)\n\n        x = self.embedding(x)\n\n        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n\n        output, state = self.gru(x)\n        output = tf.reshape(output, (-1, output.shape[2]))\n            \n        x = self.fc(output)\n        \n        return x, state, attention_weights\n</code></pre>\n<ul>\n<li>attention</li>\n</ul>\n<pre><code class=\"language-python=\">class BahdanauAttention(tf.keras.layers.Layer):\n    def __init__(self, units):\n        super(BahdanauAttention, self).__init__()\n        self.W1 = tf.keras.layers.Dense(units)\n        self.W2 = tf.keras.layers.Dense(units)\n        self.V = tf.keras.layers.Dense(1)\n\n    def call(self, query, values):\n        hidden_with_time_axis = tf.expand_dims(query, 1)\n\n        print(values)\n        score = self.V(tf.nn.tanh(\n            self.W1(values) + self.W2(hidden_with_time_axis)))\n\n        attention_weights = tf.nn.softmax(score, axis=1)\n\n        context_vector = attention_weights * values\n        context_vector = tf.reduce_sum(context_vector, axis=1)\n\n        return context_vector, attention_weights\n</code></pre>\n<ul>\n<li>seq2seq</li>\n</ul>\n<pre><code class=\"language-python=\">class seq2seq(tf.keras.Model):\n    def __init__(self, vocab_size, embedding_dim, enc_units, dec_units, batch_sz, end_token_idx=2):    \n        super(seq2seq, self).__init__()\n        self.end_token_idx = end_token_idx\n        self.encoder = Encoder(vocab_size, embedding_dim, enc_units, batch_sz) \n        self.decoder = Decoder(vocab_size, embedding_dim, dec_units, batch_sz) \n\n    def call(self, x):\n        inp, tar = x\n        \n        enc_hidden = self.encoder.initialize_hidden_state(inp)\n        enc_output, enc_hidden = self.encoder(inp, enc_hidden)\n\n        dec_hidden = enc_hidden\n\n        predict_tokens = list()\n        for t in range(0, tar.shape[1]):\n            dec_input = tf.dtypes.cast(tf.expand_dims(tar[:, t], 1), tf.float32) \n            predictions, dec_hidden, _ = self.decoder(dec_input, dec_hidden, enc_output)\n            predict_tokens.append(tf.dtypes.cast(predictions, tf.float32))   \n        return tf.stack(predict_tokens, axis=1)\n    \n    def inference(self, x):\n        inp  = x\n\n        enc_hidden = self.encoder.initialize_hidden_state(inp)\n        enc_output, enc_hidden = self.encoder(inp, enc_hidden)\n\n        dec_hidden = enc_hidden\n        \n        dec_input = tf.expand_dims([char2idx[std_index]], 1)\n        \n        predict_tokens = list()\n        for t in range(0, MAX_SEQUENCE):\n            predictions, dec_hidden, _ = self.decoder(dec_input, dec_hidden, enc_output)\n            predict_token = tf.argmax(predictions[0])\n            \n            if predict_token == self.end_token_idx:\n                break\n            \n            predict_tokens.append(predict_token)\n            dec_input = tf.dtypes.cast(tf.expand_dims([predict_token], 0), tf.float32)   \n            \n        return tf.stack(predict_tokens, axis=0).numpy()\n</code></pre>\n",
      "id": 8
    },
    {
      "path": "2-WebRTC/APIs.md",
      "url": "2-WebRTC/APIs.html",
      "content": "WebRTC APIs\n===\n\n###### tags: `WebRTC`\n\n- WebRTC란?\n    - Real Time Communication의 약자로 웹상에서 별도의 플러그인 없이 화상서비스 뿐만아니라 peer-to-peer 데이터 공유가 가능해지는 서비스 입니다.\n    - 현재 Google Chrome, Safari, Firefox, 그리고 Opera를 지원하고 있습니다.\n    - [appr.tc](https://appr.tc/)에서 간단한 demo를 체험할 수 있습니다.\n\n- WebRTC의 주요 API 3가지\n    1. MediaStream: Accessing audio and video\n        ![](https://i.imgur.com/airoUgz.jpg)\n        ref: https://youtu.be/p2HzZkd2A40\n        ```javascript\n        const constraints = {video: true, audio: true} \n        \n        const successCallback = stream => {\n            const video = document.querySelector('video')\n            video.src = window.URL.createObjectURL(stream)\n        }\n        \n        const errorCallback = error => {\n            console.log('getUserMedia error: ', error)\n        }\n        \n        navigator.getUserMedia(constraints, successCallback, errorCallback)\n        ```\n        ```java\n        Supporting constraints\n        dictionary MediaTrackSupportedConstraints {\n          boolean width = true;\n          boolean height = true;\n          boolean aspectRatio = true;\n          boolean frameRate = true;\n          boolean facingMode = true;\n          boolean resizeMode = true;\n          boolean sampleRate = true;\n          boolean sampleSize = true;\n          boolean echoCancellation = true;\n          boolean autoGainControl = true;\n          boolean noiseSuppression = true;\n          boolean latency = true;\n          boolean channelCount = true;\n          boolean deviceId = true;\n          boolean groupId = true;\n        };\n        ```\n        [examples](http://webaudiodemos.appspot.com/)\n    2. RTCPeerConnection: Internet을 통해 다른 WebRTC endpoint로 실시간 연결\n        ![](https://i.imgur.com/MS1LpfX.jpg)\n        ref: https://www.youtube.com/watch?v=p2HzZkd2A40\n        - Signal processing\n        - Codec handling\n        - Peer to peer communication\n        - Security\n        - Bandwidth management\n        ```javascript\n        pc = new RTCPeerConnection(null)\n        pc.onaddstream = gotRemoteStream\n        pc.addStream(localStream)\n        pc.createOffer(gotOffer)\n        \n        const gotOffer = desc => {\n            pc.setLocalDescription(desc)\n            sendOffer(desc)\n        }\n        \n        const gotAnswer = desc => {\n            pc.setRemoteDescription(desc)\n        }\n        \n        const gotRemoteStream = event => {\n            attachMediaStream(remoteVideo, event.stream)\n        }\n        ```\n        [sample](https://simpl.info/rtcpeerconnection/)\n    3. RTCDataChannel: Video와 Audio뿐만 아니라 어떠한 형식의 데이터도 공유 가능\n        - Websocket과 유사함\n        - Ultra-low latency\n        - Unreliable and reliable(UDP/TCP)\n        - Secure(Data encryption)\n        ```javascript\n        const pc = new webkitRTCPeerConnection(servers, {optional: [{RtpDataChannels: true}]})\n        pc.ondatachannel = event => {\n            receiveChannel = event.channel\n            receiveChannel.onmessage = event => {\n                document.querySelector('div#receive').innerHTML = event.data\n            }\n        }\n        \n        sendChannel = pc.createDataChannel('sendDataChannel', {reliable: false})\n        document.querySelector('button#send').onclick = () => {\n            const data = document.querySelector('textarea#send').value\n            sendChannel.send()\n        }\n        ```\n        [sample](https://simpl.info/rtcdatachannel/)\n",
      "html": "<h1 id=\"webrtc-apis\">WebRTC APIs <a class=\"heading-anchor-permalink\" href=\"#webrtc-apis\">#</a></h1>\n<h6 id=\"tags%3A-webrtc\">tags: <code>WebRTC</code> <a class=\"heading-anchor-permalink\" href=\"#tags%3A-webrtc\">#</a></h6>\n<ul>\n<li>\n<p>WebRTC란?</p>\n<ul>\n<li>Real Time Communication의 약자로 웹상에서 별도의 플러그인 없이 화상서비스 뿐만아니라 peer-to-peer 데이터 공유가 가능해지는 서비스 입니다.</li>\n<li>현재 Google Chrome, Safari, Firefox, 그리고 Opera를 지원하고 있습니다.</li>\n<li><a href=\"https://appr.tc/\">appr.tc</a>에서 간단한 demo를 체험할 수 있습니다.</li>\n</ul>\n</li>\n<li>\n<p>WebRTC의 주요 API 3가지</p>\n<ol>\n<li>MediaStream: Accessing audio and video\n<img src=\"https://i.imgur.com/airoUgz.jpg\" alt=\"\">\nref: <a href=\"https://youtu.be/p2HzZkd2A40\">https://youtu.be/p2HzZkd2A40</a><pre><code class=\"language-javascript\">const constraints = {video: true, audio: true} \n\nconst successCallback = stream =&gt; {\n    const video = document.querySelector('video')\n    video.src = window.URL.createObjectURL(stream)\n}\n\nconst errorCallback = error =&gt; {\n    console.log('getUserMedia error: ', error)\n}\n\nnavigator.getUserMedia(constraints, successCallback, errorCallback)\n</code></pre>\n<pre><code class=\"language-java\">Supporting constraints\ndictionary MediaTrackSupportedConstraints {\n  boolean width = true;\n  boolean height = true;\n  boolean aspectRatio = true;\n  boolean frameRate = true;\n  boolean facingMode = true;\n  boolean resizeMode = true;\n  boolean sampleRate = true;\n  boolean sampleSize = true;\n  boolean echoCancellation = true;\n  boolean autoGainControl = true;\n  boolean noiseSuppression = true;\n  boolean latency = true;\n  boolean channelCount = true;\n  boolean deviceId = true;\n  boolean groupId = true;\n};\n</code></pre>\n<a href=\"http://webaudiodemos.appspot.com/\">examples</a></li>\n<li>RTCPeerConnection: Internet을 통해 다른 WebRTC endpoint로 실시간 연결\n<img src=\"https://i.imgur.com/MS1LpfX.jpg\" alt=\"\">\nref: <a href=\"https://www.youtube.com/watch?v=p2HzZkd2A40\">https://www.youtube.com/watch?v=p2HzZkd2A40</a>\n<ul>\n<li>Signal processing</li>\n<li>Codec handling</li>\n<li>Peer to peer communication</li>\n<li>Security</li>\n<li>Bandwidth management</li>\n</ul>\n<pre><code class=\"language-javascript\">pc = new RTCPeerConnection(null)\npc.onaddstream = gotRemoteStream\npc.addStream(localStream)\npc.createOffer(gotOffer)\n\nconst gotOffer = desc =&gt; {\n    pc.setLocalDescription(desc)\n    sendOffer(desc)\n}\n\nconst gotAnswer = desc =&gt; {\n    pc.setRemoteDescription(desc)\n}\n\nconst gotRemoteStream = event =&gt; {\n    attachMediaStream(remoteVideo, event.stream)\n}\n</code></pre>\n<a href=\"https://simpl.info/rtcpeerconnection/\">sample</a></li>\n<li>RTCDataChannel: Video와 Audio뿐만 아니라 어떠한 형식의 데이터도 공유 가능\n<ul>\n<li>Websocket과 유사함</li>\n<li>Ultra-low latency</li>\n<li>Unreliable and reliable(UDP/TCP)</li>\n<li>Secure(Data encryption)</li>\n</ul>\n<pre><code class=\"language-javascript\">const pc = new webkitRTCPeerConnection(servers, {optional: [{RtpDataChannels: true}]})\npc.ondatachannel = event =&gt; {\n    receiveChannel = event.channel\n    receiveChannel.onmessage = event =&gt; {\n        document.querySelector('div#receive').innerHTML = event.data\n    }\n}\n\nsendChannel = pc.createDataChannel('sendDataChannel', {reliable: false})\ndocument.querySelector('button#send').onclick = () =&gt; {\n    const data = document.querySelector('textarea#send').value\n    sendChannel.send()\n}\n</code></pre>\n<a href=\"https://simpl.info/rtcdatachannel/\">sample</a></li>\n</ol>\n</li>\n</ul>\n",
      "id": 9
    },
    {
      "path": "2-WebRTC/Mechanism.md",
      "url": "2-WebRTC/Mechanism.html",
      "content": "WebRTC Mechanism\n===\n\n###### tags: `WebRTC`\n\n- Signaling\n    - WebRTC는 RTCPeerConnection API를 활용하여 데이터를 스트리밍합니다. 하지만 그전에 어떤 사용자에게 데이터를 전송할지 coordination을 포함하진 않습니다.\n        따라서 우리는 올바른 사용자간 peer-to-peer 환경을 제공하기 위해 signaling을 사용합니다.\n    - Protocol에 제약은 없으며 SIP, XMPP, Socket.io등 다양하게 활용하시면 됩니다.\n    - [appr.tc](https://appr.tc/)는 XHR과 Channel API를 사용한 간단한 예제입니다.\n    ![](https://www.html5rocks.com/en/tutorials/webrtc/basics/jsep.png)\n    - Signaling을 통해 교환되는 정보 4가지\n        1. 통신을 열고 닫는데 사용되는 세션 컨트롤 및 에러 메세지\n        2. 코덱이나 코덱 설정, 대역폭, 미디어 타입 같은 미디어 메타데이터\n        3. 보안 연결을 수립하기 위해 사용되는 키 데이터\n        4. 호스트의 IP 주소와 포트 같은 네트워크 데이터\n\n    - 브라우저는 signaling을 통해 연결을 맺을 상대방의 통신 정보를 어플리케이션에서 습득 후 peer to peer로 미디어 및 데이터를 전송할 수 있는 권한을 얻는다.\n\n- 필요한 지식\n    - NAT은 공인망과 내부망이 분리되어 있는 환경에서 각 망의 IP:Port를 맵핑해주는 역할을 한다.\n        - Normal(Full Cone) NAT\n          내부서버A에서 공유기를 거쳐 IP_A:Port_A인 external IP와 맵핑되어 외부서버로 패킷이 전달했다면 어떠한 외부서버도 IP_A:Port_A를 통해 내부서버A로 패킷을 전달할 수 있다.\n        - Restricted Cone NAT: \n          내부서버A(IP_A:Port_A)에서 외부서버B(IP_B:Port_B)로 패킷을 전달했다면, IP_A:Port_A를 통해 내부서버A로 패킷을 전달하려는 외부서버는 IP_B주소를 가지고 있어야만하며 Port는 무관하다.\n        - Port Restricted Cone NAT\n          Restricted Cone NAT과 방식은 같으며 제약이 Port까지 추가된다.\n        - Symmetric NAT\n          외부서버에서 내부서버로 패킷을 보낼때마다 다른 NAT맵핑을 사용하게 되는데. Restricted Cone NAT은 external Port가 일정하지만 symmetric NAT은 접속하는 외부서버에 따라 external Port가 다르다.\n\n    - STUN(Session Traversal Utilities for NAT)는 Peer간 통신을 하는데 public종단을 거칠 때에 NAT상에 맵핑된 peer의 접속정보(IP주소)를 열람하는 역할을 한다.\n        ![](https://i.imgur.com/luRtnFf.png)\n\n    - TURN(Traversal Using Relays around NAT)는 STUN이 IP주소를 확인하는 과정을 실패하여 Peer간 직접 통신이 어려울 경우 NAT사이에서 데이터를 전달해 줄 TURN서버를 사용하게 된다. TURN은 별도의 공용 주소를 사용하며 데이터를 전달해주기 때문에 peer to peer 직접 연결하는 것보다 컴퓨팅 자원이 소모 된다. \n       ![](https://i.imgur.com/8uwDQXy.png)\n\n- Steps\n    ![](https://i.imgur.com/dEcrHuL.png)\n    1. Peer A와 Peer B는 Signaling Server를 통해 자신의 SDP(video / audio에 대한 데이터)를 상대방에게 전송한다.\n    2. 자신의 SDP는 RTCPeerConnection의 localDescription으로 등록하고 상대방의 SDP는 remoteDescription으로 등록한다.\n    3. local description이 등록되는 시점에 STUN/TURN서버를 통해 iceCandidate이 생성되는데 이 candidate에는 자신의 host정보가 담겨 있다.\n    4. 이 정보를 Signaling Server를 통해 다시 서로에게 전달을 하면 PeerConnection의 addIceCandidate으로 서로의 candidate을 등록하게 된다.\n    5. 이렇게 SDP(Media에 대한 정보)와 Candidate(Host에 대한 정보)를 Peer간 주고받으면 모든 준비가 끝나며 PeerConnection 객체의 ontrack 이벤트를 통해 서로의 Media Stream데이터를 전달 받을 수 있게된다.\n\nrefs:\n- https://www.youtube.com/watch?v=p2HzZkd2A40\n- https://juyoung-1008.tistory.com/27",
      "html": "<h1 id=\"webrtc-mechanism\">WebRTC Mechanism <a class=\"heading-anchor-permalink\" href=\"#webrtc-mechanism\">#</a></h1>\n<h6 id=\"tags%3A-webrtc\">tags: <code>WebRTC</code> <a class=\"heading-anchor-permalink\" href=\"#tags%3A-webrtc\">#</a></h6>\n<ul>\n<li>\n<p>Signaling</p>\n<ul>\n<li>\n<p>WebRTC는 RTCPeerConnection API를 활용하여 데이터를 스트리밍합니다. 하지만 그전에 어떤 사용자에게 데이터를 전송할지 coordination을 포함하진 않습니다.\n따라서 우리는 올바른 사용자간 peer-to-peer 환경을 제공하기 위해 signaling을 사용합니다.</p>\n</li>\n<li>\n<p>Protocol에 제약은 없으며 SIP, XMPP, Socket.io등 다양하게 활용하시면 됩니다.</p>\n</li>\n<li>\n<p><a href=\"https://appr.tc/\">appr.tc</a>는 XHR과 Channel API를 사용한 간단한 예제입니다.\n<img src=\"https://www.html5rocks.com/en/tutorials/webrtc/basics/jsep.png\" alt=\"\"></p>\n</li>\n<li>\n<p>Signaling을 통해 교환되는 정보 4가지</p>\n<ol>\n<li>통신을 열고 닫는데 사용되는 세션 컨트롤 및 에러 메세지</li>\n<li>코덱이나 코덱 설정, 대역폭, 미디어 타입 같은 미디어 메타데이터</li>\n<li>보안 연결을 수립하기 위해 사용되는 키 데이터</li>\n<li>호스트의 IP 주소와 포트 같은 네트워크 데이터</li>\n</ol>\n</li>\n<li>\n<p>브라우저는 signaling을 통해 연결을 맺을 상대방의 통신 정보를 어플리케이션에서 습득 후 peer to peer로 미디어 및 데이터를 전송할 수 있는 권한을 얻는다.</p>\n</li>\n</ul>\n</li>\n<li>\n<p>필요한 지식</p>\n<ul>\n<li>\n<p>NAT은 공인망과 내부망이 분리되어 있는 환경에서 각 망의 IP:Port를 맵핑해주는 역할을 한다.</p>\n<ul>\n<li>Normal(Full Cone) NAT\n내부서버A에서 공유기를 거쳐 IP_A:Port_A인 external IP와 맵핑되어 외부서버로 패킷이 전달했다면 어떠한 외부서버도 IP_A:Port_A를 통해 내부서버A로 패킷을 전달할 수 있다.</li>\n<li>Restricted Cone NAT:\n내부서버A(IP_A:Port_A)에서 외부서버B(IP_B:Port_B)로 패킷을 전달했다면, IP_A:Port_A를 통해 내부서버A로 패킷을 전달하려는 외부서버는 IP_B주소를 가지고 있어야만하며 Port는 무관하다.</li>\n<li>Port Restricted Cone NAT\nRestricted Cone NAT과 방식은 같으며 제약이 Port까지 추가된다.</li>\n<li>Symmetric NAT\n외부서버에서 내부서버로 패킷을 보낼때마다 다른 NAT맵핑을 사용하게 되는데. Restricted Cone NAT은 external Port가 일정하지만 symmetric NAT은 접속하는 외부서버에 따라 external Port가 다르다.</li>\n</ul>\n</li>\n<li>\n<p>STUN(Session Traversal Utilities for NAT)는 Peer간 통신을 하는데 public종단을 거칠 때에 NAT상에 맵핑된 peer의 접속정보(IP주소)를 열람하는 역할을 한다.\n<img src=\"https://i.imgur.com/luRtnFf.png\" alt=\"\"></p>\n</li>\n<li>\n<p>TURN(Traversal Using Relays around NAT)는 STUN이 IP주소를 확인하는 과정을 실패하여 Peer간 직접 통신이 어려울 경우 NAT사이에서 데이터를 전달해 줄 TURN서버를 사용하게 된다. TURN은 별도의 공용 주소를 사용하며 데이터를 전달해주기 때문에 peer to peer 직접 연결하는 것보다 컴퓨팅 자원이 소모 된다.\n<img src=\"https://i.imgur.com/8uwDQXy.png\" alt=\"\"></p>\n</li>\n</ul>\n</li>\n<li>\n<p>Steps\n<img src=\"https://i.imgur.com/dEcrHuL.png\" alt=\"\"></p>\n<ol>\n<li>Peer A와 Peer B는 Signaling Server를 통해 자신의 SDP(video / audio에 대한 데이터)를 상대방에게 전송한다.</li>\n<li>자신의 SDP는 RTCPeerConnection의 localDescription으로 등록하고 상대방의 SDP는 remoteDescription으로 등록한다.</li>\n<li>local description이 등록되는 시점에 STUN/TURN서버를 통해 iceCandidate이 생성되는데 이 candidate에는 자신의 host정보가 담겨 있다.</li>\n<li>이 정보를 Signaling Server를 통해 다시 서로에게 전달을 하면 PeerConnection의 addIceCandidate으로 서로의 candidate을 등록하게 된다.</li>\n<li>이렇게 SDP(Media에 대한 정보)와 Candidate(Host에 대한 정보)를 Peer간 주고받으면 모든 준비가 끝나며 PeerConnection 객체의 ontrack 이벤트를 통해 서로의 Media Stream데이터를 전달 받을 수 있게된다.</li>\n</ol>\n</li>\n</ul>\n<p>refs:</p>\n<ul>\n<li><a href=\"https://www.youtube.com/watch?v=p2HzZkd2A40\">https://www.youtube.com/watch?v=p2HzZkd2A40</a></li>\n<li><a href=\"https://juyoung-1008.tistory.com/27\">https://juyoung-1008.tistory.com/27</a></li>\n</ul>\n",
      "id": 10
    },
    {
      "path": "2-WebRTC/Signaling.md",
      "url": "2-WebRTC/Signaling.html",
      "content": "Signaling Server\n===\n\n###### tags: `WebRTC`\n\n- NestJS기반으로 구현 [Reference](https://docs.nestjs.com/)\n- Socket.io를 사용해서 signaling server를 구축해 보았다.\n  Signaling server란 WebRTC에서 Peer간 자신의 네트워크 정보 및 Communication에 필요한 각종 정보를 주고 받기 위한 코디네이터라 할 수 있다.\n  \n- Socket.io기반으로 채팅방을 채널별로 구분해 놓았고, Peer간의 정보를 해당 채팅방에 접속해 있는 모든 유저와 공유할 수 있도록 broadcasting 해주고 있다. [line 46]\n\n- 미디어 데이터에 대한 정보는 offer SDP와 answer SDP로 구분되는데, offer는 전화를 시도한측 answer는 응답한 측이라고 이해하면 쉽다. [line 51, 61]\n\n- Client에서 RTCPeerConnection을 통해 iceCandidate정보가 생성이 되면 peer간 send-candidate 채널을 통해 candidate정보를 넘겨주고 candidate정보에는 각 peer의 호스트 정보가 담겨있다. [line 21]\n\n```javascript=\nimport {\n    OnGatewayDisconnect,\n    OnGatewayInit,\n    SubscribeMessage,\n    WebSocketGateway,\n    WebSocketServer,\n} from '@nestjs/websockets'\nimport { Socket } from 'socket.io'\nimport { Server } from 'ws'\nimport { Logger } from '@nestjs/common'\n\n@WebSocketGateway({ namespace: 'chat'})\nexport class MessageGateway implements OnGatewayInit, OnGatewayDisconnect {\n    @WebSocketServer() server: Server\n\n    private activeSockets: { room: string; name: string, id: string }[] = []\n\n    private logger: Logger = new Logger('MessageGateway')\n\n    @SubscribeMessage('send-candidate')\n    public sendCandidate(client: Socket, data: any): void {\n        client.to(data.to).emit('receive-candidate', {\n            candidate: data.candidate,\n            socket: client.id,\n            name: data.name\n        })\n    }\n\n    @SubscribeMessage('joinRoom')\n    public joinRoom(client: Socket, info: any): void {\n        const existingSocket = this.activeSockets?.find(\n            (socket) => socket.room === info.roomName && socket.id === client.id,\n        )\n\n        if (!existingSocket) {\n            this.activeSockets = [...this.activeSockets, { id: client.id, name: info.name, room: info.roomName }]\n        }\n\n        this.logger.log(`Client ${client.id} joined ${info.roomName}`)\n\n        client.join(info.roomName)\n\n        const users = this.activeSockets\n            .filter((socket) => socket.room === info.roomName)\n            .map((existingSocket) => existingSocket.name)\n        client.to(info.roomName).broadcast.emit('joined-users', users)\n        client.emit('joined-users', users)\n    }\n\n    @SubscribeMessage('call-user')\n    public callUser(client: Socket, data: any): void {\n        console.log('calling users from ', data.name, ' to ', data.to)\n        client.to(data.to).emit('call-made', {\n            offer: data.offer,\n            name: data.name,\n            socket: client.id,\n        })\n    }\n\n    @SubscribeMessage('make-answer')\n    public makeAnswer(client: Socket, data: any): void {\n        client.to(data.to).emit('answer-made', {\n            answer: data.answer,\n            name: data.name,\n            socket: client.id,\n        })\n    }\n\n    @SubscribeMessage('reject-call')\n    public rejectCall(client: Socket, data: any): void {\n        client.to(data.from).emit('call-rejected', {\n            socket: client.id,\n        })\n    }\n\n    public afterInit(server: Server): void {\n        this.logger.log('Init')\n    }\n\n    public handleDisconnect(client: Socket): void {\n        const existingSocket = this.activeSockets.find(\n            (socket) => socket.id === client.id,\n        )\n\n        if (!existingSocket) return\n        this.activeSockets = this.activeSockets.filter(\n            (socket) => socket.id !== client.id,\n        )\n\n        client.to(existingSocket.room).emit('joined-users', {\n            users: this.activeSockets\n                .filter((socket) => socket.room === existingSocket.room)\n                .map((existingSocket) => existingSocket.name),\n        })\n\n        this.logger.log(`Client disconnected: ${client.id}`)\n    }\n}\n\n```",
      "html": "<h1 id=\"signaling-server\">Signaling Server <a class=\"heading-anchor-permalink\" href=\"#signaling-server\">#</a></h1>\n<h6 id=\"tags%3A-webrtc\">tags: <code>WebRTC</code> <a class=\"heading-anchor-permalink\" href=\"#tags%3A-webrtc\">#</a></h6>\n<ul>\n<li>\n<p>NestJS기반으로 구현 <a href=\"https://docs.nestjs.com/\">Reference</a></p>\n</li>\n<li>\n<p>Socket.io를 사용해서 signaling server를 구축해 보았다.\nSignaling server란 WebRTC에서 Peer간 자신의 네트워크 정보 및 Communication에 필요한 각종 정보를 주고 받기 위한 코디네이터라 할 수 있다.</p>\n</li>\n<li>\n<p>Socket.io기반으로 채팅방을 채널별로 구분해 놓았고, Peer간의 정보를 해당 채팅방에 접속해 있는 모든 유저와 공유할 수 있도록 broadcasting 해주고 있다. [line 46]</p>\n</li>\n<li>\n<p>미디어 데이터에 대한 정보는 offer SDP와 answer SDP로 구분되는데, offer는 전화를 시도한측 answer는 응답한 측이라고 이해하면 쉽다. [line 51, 61]</p>\n</li>\n<li>\n<p>Client에서 RTCPeerConnection을 통해 iceCandidate정보가 생성이 되면 peer간 send-candidate 채널을 통해 candidate정보를 넘겨주고 candidate정보에는 각 peer의 호스트 정보가 담겨있다. [line 21]</p>\n</li>\n</ul>\n<pre><code class=\"language-javascript=\">import {\n    OnGatewayDisconnect,\n    OnGatewayInit,\n    SubscribeMessage,\n    WebSocketGateway,\n    WebSocketServer,\n} from '@nestjs/websockets'\nimport { Socket } from 'socket.io'\nimport { Server } from 'ws'\nimport { Logger } from '@nestjs/common'\n\n@WebSocketGateway({ namespace: 'chat'})\nexport class MessageGateway implements OnGatewayInit, OnGatewayDisconnect {\n    @WebSocketServer() server: Server\n\n    private activeSockets: { room: string; name: string, id: string }[] = []\n\n    private logger: Logger = new Logger('MessageGateway')\n\n    @SubscribeMessage('send-candidate')\n    public sendCandidate(client: Socket, data: any): void {\n        client.to(data.to).emit('receive-candidate', {\n            candidate: data.candidate,\n            socket: client.id,\n            name: data.name\n        })\n    }\n\n    @SubscribeMessage('joinRoom')\n    public joinRoom(client: Socket, info: any): void {\n        const existingSocket = this.activeSockets?.find(\n            (socket) =&gt; socket.room === info.roomName &amp;&amp; socket.id === client.id,\n        )\n\n        if (!existingSocket) {\n            this.activeSockets = [...this.activeSockets, { id: client.id, name: info.name, room: info.roomName }]\n        }\n\n        this.logger.log(`Client ${client.id} joined ${info.roomName}`)\n\n        client.join(info.roomName)\n\n        const users = this.activeSockets\n            .filter((socket) =&gt; socket.room === info.roomName)\n            .map((existingSocket) =&gt; existingSocket.name)\n        client.to(info.roomName).broadcast.emit('joined-users', users)\n        client.emit('joined-users', users)\n    }\n\n    @SubscribeMessage('call-user')\n    public callUser(client: Socket, data: any): void {\n        console.log('calling users from ', data.name, ' to ', data.to)\n        client.to(data.to).emit('call-made', {\n            offer: data.offer,\n            name: data.name,\n            socket: client.id,\n        })\n    }\n\n    @SubscribeMessage('make-answer')\n    public makeAnswer(client: Socket, data: any): void {\n        client.to(data.to).emit('answer-made', {\n            answer: data.answer,\n            name: data.name,\n            socket: client.id,\n        })\n    }\n\n    @SubscribeMessage('reject-call')\n    public rejectCall(client: Socket, data: any): void {\n        client.to(data.from).emit('call-rejected', {\n            socket: client.id,\n        })\n    }\n\n    public afterInit(server: Server): void {\n        this.logger.log('Init')\n    }\n\n    public handleDisconnect(client: Socket): void {\n        const existingSocket = this.activeSockets.find(\n            (socket) =&gt; socket.id === client.id,\n        )\n\n        if (!existingSocket) return\n        this.activeSockets = this.activeSockets.filter(\n            (socket) =&gt; socket.id !== client.id,\n        )\n\n        client.to(existingSocket.room).emit('joined-users', {\n            users: this.activeSockets\n                .filter((socket) =&gt; socket.room === existingSocket.room)\n                .map((existingSocket) =&gt; existingSocket.name),\n        })\n\n        this.logger.log(`Client disconnected: ${client.id}`)\n    }\n}\n\n</code></pre>\n",
      "id": 11
    },
    {
      "path": "3-Azure/App Service Warmer.md",
      "url": "3-Azure/App Service Warmer.html",
      "content": "App Service Warmer\n===\n\n```bash\n*/15 * * * * /usr/bin/curl -s ${backend server url} -w \"\\n\" >> ${log file path}\n```\n\n- Azure App Service는 20분의 idle시간 이후 리소스를 다른 프로세스로 뺏기기 때문에 해당 서버를 Keep Warm시키기 위해 15분마다 http 호출을 해준다.\n- curl에 대한 로그를 로그파일에 쌓는 방법은 위 처럼 >> 명령으로 새로운 로그를 append 시켜주며 새로 append된 로그는 \"\\n\" 캐릭터로 new line에 작성되도록 한다.",
      "html": "<h1 id=\"app-service-warmer\">App Service Warmer <a class=\"heading-anchor-permalink\" href=\"#app-service-warmer\">#</a></h1>\n<pre><code class=\"language-bash\">*/15 * * * * /usr/bin/curl -s ${backend server url} -w &quot;\\n&quot; &gt;&gt; ${log file path}\n</code></pre>\n<ul>\n<li>Azure App Service는 20분의 idle시간 이후 리소스를 다른 프로세스로 뺏기기 때문에 해당 서버를 Keep Warm시키기 위해 15분마다 http 호출을 해준다.</li>\n<li>curl에 대한 로그를 로그파일에 쌓는 방법은 위 처럼 &gt;&gt; 명령으로 새로운 로그를 append 시켜주며 새로 append된 로그는 “\\n” 캐릭터로 new line에 작성되도록 한다.</li>\n</ul>\n",
      "id": 12
    },
    {
      "path": "3-Azure/Deployment.md",
      "url": "3-Azure/Deployment.html",
      "content": "Kudu Deployment\n===\n\n###### tags: `azure`\n\n- Azure App Service 배포 셋팅\n    1. 배포 센터(왼쪽 메뉴) > 설정(상단 메뉴) > git clone URI 복사\n        ![](https://i.imgur.com/96JuJBI.png)   \n    2. git remote에 azure repository 등록\n        ```shell=\n        git remote add azure ${uri}\n        ```\n    3. deploy\n        ```shell=\n        git push --force azure HEAD:master\n        ```\n        ![](https://i.imgur.com/1ipqh8n.png)\n\n- Azure App Service로 kudu를 통해 배포할때 아래와 같은 에러가 발생할 수 있다.\n    ```shell=\n    error: RPC failed; HTTP 400 curl 22 The requested URL returned error: 400\n    fatal: the remote end hung up unexpectedly\n    fatal: the remote end hung up unexpectedly\n    ```\n    Azure Service Plan의 storage가 꽉차서 나는 오류인데 ([reference](https://github.com/microsoft/vscode-azureappservice/issues/1445))\n    ![](https://i.imgur.com/INDPuph.png)\n    위 사진 처럼 그 전에 배포했던 것이 마무리 되지 않아 storage를 잡아 먹고 있는 것을 확인할 수 있다.\n- 해결책\n    1. Storage가 여유가 생길때까지 기다리던지 Service Plan사이즈를 키워준다.\n    2. Git 연결을 끊고 다시 맺는다.",
      "html": "<h1 id=\"kudu-deployment\">Kudu Deployment <a class=\"heading-anchor-permalink\" href=\"#kudu-deployment\">#</a></h1>\n<h6 id=\"tags%3A-azure\">tags: <code>azure</code> <a class=\"heading-anchor-permalink\" href=\"#tags%3A-azure\">#</a></h6>\n<ul>\n<li>\n<p>Azure App Service 배포 셋팅</p>\n<ol>\n<li>배포 센터(왼쪽 메뉴) &gt; 설정(상단 메뉴) &gt; git clone URI 복사\n<img src=\"https://i.imgur.com/96JuJBI.png\" alt=\"\"></li>\n<li>git remote에 azure repository 등록<pre><code class=\"language-shell=\">git remote add azure ${uri}\n</code></pre>\n</li>\n<li>deploy<pre><code class=\"language-shell=\">git push --force azure HEAD:master\n</code></pre>\n<img src=\"https://i.imgur.com/1ipqh8n.png\" alt=\"\"></li>\n</ol>\n</li>\n<li>\n<p>Azure App Service로 kudu를 통해 배포할때 아래와 같은 에러가 발생할 수 있다.</p>\n<pre><code class=\"language-shell=\">error: RPC failed; HTTP 400 curl 22 The requested URL returned error: 400\nfatal: the remote end hung up unexpectedly\nfatal: the remote end hung up unexpectedly\n</code></pre>\n<p>Azure Service Plan의 storage가 꽉차서 나는 오류인데 (<a href=\"https://github.com/microsoft/vscode-azureappservice/issues/1445\">reference</a>)\n<img src=\"https://i.imgur.com/INDPuph.png\" alt=\"\">\n위 사진 처럼 그 전에 배포했던 것이 마무리 되지 않아 storage를 잡아 먹고 있는 것을 확인할 수 있다.</p>\n</li>\n<li>\n<p>해결책</p>\n<ol>\n<li>Storage가 여유가 생길때까지 기다리던지 Service Plan사이즈를 키워준다.</li>\n<li>Git 연결을 끊고 다시 맺는다.</li>\n</ol>\n</li>\n</ul>\n",
      "id": 13
    },
    {
      "path": "4-Zoom/API 사용기.md",
      "url": "4-Zoom/API 사용기.html",
      "content": "Zoom API 사용기\n===\n\n- [API LIST](https://marketplace.zoom.us/docs/api-reference/zoom-api)\n- [Client SDK Document](https://marketplace.zoom.us/docs/sdk/native-sdks/web/reference)\n- [Market Place](https://marketplace.zoom.us/)\n1. Web SDK를 활용하기 위한 절차\n    - JWT 어플리케이션 프로젝트 생성 후 API key를 발급받아야한다.\n    ![](https://i.imgur.com/itkc6V3.png)\n    - Zoom sdk에서는 기본적으로 API key와 Signature값을 요구한다.\n    ``` javascript\n    ZoomMtg.join({\n        meetingNumber: 123456789,\n        userName: 'User name',\n        userEmail: '',\n        passWord: '',\n        apiKey: 'API_KEY',\n        signature: 'SIGNATURE',\n        success: function(res){console.log(res)},\n        error: function(res){console.log(res)}\n    });\n    ```\n    - Signature 발급을 위해 Sercret 값이 필요하다.\n    ```javascript\n    ZoomMtg.generateSignature({\n        meetingNumber: 'Meeting Room Number',\n        apiKey: 'API KEY',\n        apiSecret: 'API SECRET',\n        role: 0, // 1 host, 0 participant\n        success: function(res){\n            console.log(res.result);\n        }\n    });\n    ```\n    \n2. 회의 만들기\n    - Client에 API SECRET을 노출하는 것은 위험하기 때문에 위와 같은 방법 보다는 백엔드에서 JWT을 발급 후 Zoom API와 연동하는 것이 좋다.\n      아래는 Zoom에서 권장한 SHA256기반의 jwt생성 함수다.\n    ```javascript\n    generateToken () {\n        const API_KEY = 'API_KEY'\n        const SECRET_KEY = 'SECRET_KEY'\n        const EXP_TIME = 20 * 60 * 1000\n\n        const header = {\n            alg: 'HS256',\n            typ: 'JWT'\n        }\n        const encodedHeader = Buffer.from(JSON.stringify(header)).toString('base64').replace(/=/g, '')\n\n        const payload = {\n            iss: API_KEY,\n            exp: new Date(new Date().getTime() + EXP_TIME).getTime()\n        }\n        const encodedPayload =  Buffer.from(JSON.stringify(payload)).toString('base64').replace(/=/g, '')\n\n        const message = encodedHeader + '.' + encodedPayload\n        const hmacSecret = crypto.createHmac('sha256', SECRET_KEY).update(message).digest('base64').replace(/=/g, '')\n\n        return encodedHeader + '.' + encodedPayload + '.' + hmacSecret\n    }\n    ```\n    - 회의를 만들기 위해서는 `POST https://api.zoom.us/v2/users/${userId}/meetings` API를 사용한다.\n    - Header에 Authorization 필드에 위에서 발급받은 token값을 넣는다. \n    - Body에는 회의 주제와 회의 타입을 정의해서 API를 호출하면 되는데 타입 종류는 다음과 같다.\n        - 지금바로 진행할 회의\n        - 시작시간을 설정하고 추후해 진행할 회의\n        - 반복으로 진행할 회의\n        - 반복으로 진행할 회의이며 진행시간이 FIXED된 회의\n\n3. 회의 참가하기\n    - 위에서 생성된 회의를 Client에서 참가하는 방법을 알아볼텐데 필자는 Vue를 사용했다.\n    - 먼저 Zoom SDK를 사용하기 위해 library 설치한다.\n    ```\n    npm install --save-dev @zoomus/websdk\n    ```\n    - Client에서 ZoomMtg 객체를 import만 해주어도 화면이 표시되는 것을 볼 수 있다.\n    ```javascript\n    import {ZoomMtg} from '@zoomus/websdk'\n    ```\n    - Zoom에서 필요한 클라이언트 라이브러리를 모두 준비해 주기위해 아래 스크립트도 추가해준다.\n    ```javascript\n    ZoomMtg.setZoomJSLib('https://source.zoom.us/1.9.0/lib', '/av')\n    ZoomMtg.preLoadWasm()\n    ZoomMtg.prepareJssdk()\n    ```\n    \n    ```javascript\n    ZoomMtg.init({\n        leaveUrl: './zoom', //required\n        success: response => {\n            ZoomMtg.join({\n                meetingNumber: room number,\n                userName: 'USER NAME',\n                userEmail: 'EMAIL ADDRESS',\n                passWord: 'PASS CODE',\n                apiKey: 'API KEY',\n                signature: 'SIGNATURE',\n                success: function(res){},\n                error: function(res){}\n            })\n        }\n    })\n    ```\n    - 여기서 signature값을 생성하기 위해서는 API Secret을 사용해야하는데 API Secret이 Client 소스에 노출되는 것을 방지하기 위해 backend에서 signature 생성해 주었다.\n    ```javascript\n    generateSignature (meetingNumber: string) {\n        const ts = new Date().getTime() - 30000;\n        const message = Buffer.from(this.API_KEY + meetingNumber + ts + Roles.ATTENDEE).toString('base64')\n        const hash = crypto.createHmac('sha256', this.SECRET_KEY).update(message).digest('base64')\n\n        return base64JS.Base64.encodeURI(this.API_KEY + '.' + meetingNumber + '.' + ts + '.' + Roles.ATTENDEE + '.' + hash)\n    }\n    ```\n",
      "html": "<h1 id=\"zoom-api-%EC%82%AC%EC%9A%A9%EA%B8%B0\">Zoom API 사용기 <a class=\"heading-anchor-permalink\" href=\"#zoom-api-%EC%82%AC%EC%9A%A9%EA%B8%B0\">#</a></h1>\n<ul>\n<li><a href=\"https://marketplace.zoom.us/docs/api-reference/zoom-api\">API LIST</a></li>\n<li><a href=\"https://marketplace.zoom.us/docs/sdk/native-sdks/web/reference\">Client SDK Document</a></li>\n<li><a href=\"https://marketplace.zoom.us/\">Market Place</a></li>\n</ul>\n<ol>\n<li>\n<p>Web SDK를 활용하기 위한 절차</p>\n<ul>\n<li>JWT 어플리케이션 프로젝트 생성 후 API key를 발급받아야한다.\n<img src=\"https://i.imgur.com/itkc6V3.png\" alt=\"\"></li>\n<li>Zoom sdk에서는 기본적으로 API key와 Signature값을 요구한다.</li>\n</ul>\n<pre><code class=\"language-javascript\">ZoomMtg.join({\n    meetingNumber: 123456789,\n    userName: 'User name',\n    userEmail: '',\n    passWord: '',\n    apiKey: 'API_KEY',\n    signature: 'SIGNATURE',\n    success: function(res){console.log(res)},\n    error: function(res){console.log(res)}\n});\n</code></pre>\n<ul>\n<li>Signature 발급을 위해 Sercret 값이 필요하다.</li>\n</ul>\n<pre><code class=\"language-javascript\">ZoomMtg.generateSignature({\n    meetingNumber: 'Meeting Room Number',\n    apiKey: 'API KEY',\n    apiSecret: 'API SECRET',\n    role: 0, // 1 host, 0 participant\n    success: function(res){\n        console.log(res.result);\n    }\n});\n</code></pre>\n</li>\n<li>\n<p>회의 만들기</p>\n<ul>\n<li>Client에 API SECRET을 노출하는 것은 위험하기 때문에 위와 같은 방법 보다는 백엔드에서 JWT을 발급 후 Zoom API와 연동하는 것이 좋다.\n아래는 Zoom에서 권장한 SHA256기반의 jwt생성 함수다.</li>\n</ul>\n<pre><code class=\"language-javascript\">generateToken () {\n    const API_KEY = 'API_KEY'\n    const SECRET_KEY = 'SECRET_KEY'\n    const EXP_TIME = 20 * 60 * 1000\n\n    const header = {\n        alg: 'HS256',\n        typ: 'JWT'\n    }\n    const encodedHeader = Buffer.from(JSON.stringify(header)).toString('base64').replace(/=/g, '')\n\n    const payload = {\n        iss: API_KEY,\n        exp: new Date(new Date().getTime() + EXP_TIME).getTime()\n    }\n    const encodedPayload =  Buffer.from(JSON.stringify(payload)).toString('base64').replace(/=/g, '')\n\n    const message = encodedHeader + '.' + encodedPayload\n    const hmacSecret = crypto.createHmac('sha256', SECRET_KEY).update(message).digest('base64').replace(/=/g, '')\n\n    return encodedHeader + '.' + encodedPayload + '.' + hmacSecret\n}\n</code></pre>\n<ul>\n<li>회의를 만들기 위해서는 <code>POST https://api.zoom.us/v2/users/${userId}/meetings</code> API를 사용한다.</li>\n<li>Header에 Authorization 필드에 위에서 발급받은 token값을 넣는다.</li>\n<li>Body에는 회의 주제와 회의 타입을 정의해서 API를 호출하면 되는데 타입 종류는 다음과 같다.\n<ul>\n<li>지금바로 진행할 회의</li>\n<li>시작시간을 설정하고 추후해 진행할 회의</li>\n<li>반복으로 진행할 회의</li>\n<li>반복으로 진행할 회의이며 진행시간이 FIXED된 회의</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>회의 참가하기</p>\n<ul>\n<li>위에서 생성된 회의를 Client에서 참가하는 방법을 알아볼텐데 필자는 Vue를 사용했다.</li>\n<li>먼저 Zoom SDK를 사용하기 위해 library 설치한다.</li>\n</ul>\n<pre><code>npm install --save-dev @zoomus/websdk\n</code></pre>\n<ul>\n<li>Client에서 ZoomMtg 객체를 import만 해주어도 화면이 표시되는 것을 볼 수 있다.</li>\n</ul>\n<pre><code class=\"language-javascript\">import {ZoomMtg} from '@zoomus/websdk'\n</code></pre>\n<ul>\n<li>Zoom에서 필요한 클라이언트 라이브러리를 모두 준비해 주기위해 아래 스크립트도 추가해준다.</li>\n</ul>\n<pre><code class=\"language-javascript\">ZoomMtg.setZoomJSLib('https://source.zoom.us/1.9.0/lib', '/av')\nZoomMtg.preLoadWasm()\nZoomMtg.prepareJssdk()\n</code></pre>\n<pre><code class=\"language-javascript\">ZoomMtg.init({\n    leaveUrl: './zoom', //required\n    success: response =&gt; {\n        ZoomMtg.join({\n            meetingNumber: room number,\n            userName: 'USER NAME',\n            userEmail: 'EMAIL ADDRESS',\n            passWord: 'PASS CODE',\n            apiKey: 'API KEY',\n            signature: 'SIGNATURE',\n            success: function(res){},\n            error: function(res){}\n        })\n    }\n})\n</code></pre>\n<ul>\n<li>여기서 signature값을 생성하기 위해서는 API Secret을 사용해야하는데 API Secret이 Client 소스에 노출되는 것을 방지하기 위해 backend에서 signature 생성해 주었다.</li>\n</ul>\n<pre><code class=\"language-javascript\">generateSignature (meetingNumber: string) {\n    const ts = new Date().getTime() - 30000;\n    const message = Buffer.from(this.API_KEY + meetingNumber + ts + Roles.ATTENDEE).toString('base64')\n    const hash = crypto.createHmac('sha256', this.SECRET_KEY).update(message).digest('base64')\n\n    return base64JS.Base64.encodeURI(this.API_KEY + '.' + meetingNumber + '.' + ts + '.' + Roles.ATTENDEE + '.' + hash)\n}\n</code></pre>\n</li>\n</ol>\n",
      "id": 14
    },
    {
      "path": "5-Flutter/1-Setup.md",
      "url": "5-Flutter/1-Setup.html",
      "content": "Chapter 1. Flutter 시작하기\n===\n###### tags: `Flutter` `Android Studio`\n\n1. Android Studio 셋팅\n    - 다운로드 https://developer.android.com/studio?hl=ko\n    - 플러그인 설치\n      ![](https://i.imgur.com/RBXLh3O.jpg)\n    - flutter & dart 설치\n      ![](https://i.imgur.com/cNVG2L6.png)\n\n2. 프로젝트 생성\n    - Flutter 프로젝트 만들기\n      ![](https://i.imgur.com/IgFDXMQ.png)\n    - 프로젝트 종류 -> Application 선택\n      ![](https://i.imgur.com/EEsYN1G.png)\n      a. Application: 어플리케이션 개발\n      b. Plugin: Native API를 사용\n      c. Package: Flutter App에 적용될 컴포넌트 개발\n      d. Module: Native App에 적용될 컴포넌트 개발\n    - 프로젝트 셋팅 & SDK 설치\n      ![](https://i.imgur.com/eo5T9It.png)\n\n3. Simulator 셋팅\n    - iOS simulator 실행\n      ![](https://i.imgur.com/vK85Ojw.png)\n    - 빠릿 빠릿한 iphone 12 max\n      ![](https://i.imgur.com/56dqoww.jpg)\n    - 코드 빌드 및 실행\n      ![](https://i.imgur.com/al6lAuY.png)\n      실행한 iphone이 안보이면\n     `sudo xcode-select --switch /Applications/Xcode.app/Contents/Developer`",
      "html": "<h1 id=\"chapter-1.-flutter-%EC%8B%9C%EC%9E%91%ED%95%98%EA%B8%B0\">Chapter 1. Flutter 시작하기 <a class=\"heading-anchor-permalink\" href=\"#chapter-1.-flutter-%EC%8B%9C%EC%9E%91%ED%95%98%EA%B8%B0\">#</a></h1>\n<h6 id=\"tags%3A-flutter-android-studio\">tags: <code>Flutter</code> <code>Android Studio</code> <a class=\"heading-anchor-permalink\" href=\"#tags%3A-flutter-android-studio\">#</a></h6>\n<ol>\n<li>\n<p>Android Studio 셋팅</p>\n<ul>\n<li>다운로드 <a href=\"https://developer.android.com/studio?hl=ko\">https://developer.android.com/studio?hl=ko</a></li>\n<li>플러그인 설치\n<img src=\"https://i.imgur.com/RBXLh3O.jpg\" alt=\"\"></li>\n<li>flutter &amp; dart 설치\n<img src=\"https://i.imgur.com/cNVG2L6.png\" alt=\"\"></li>\n</ul>\n</li>\n<li>\n<p>프로젝트 생성</p>\n<ul>\n<li>Flutter 프로젝트 만들기\n<img src=\"https://i.imgur.com/IgFDXMQ.png\" alt=\"\"></li>\n<li>프로젝트 종류 -&gt; Application 선택\n<img src=\"https://i.imgur.com/EEsYN1G.png\" alt=\"\">\na. Application: 어플리케이션 개발\nb. Plugin: Native API를 사용\nc. Package: Flutter App에 적용될 컴포넌트 개발\nd. Module: Native App에 적용될 컴포넌트 개발</li>\n<li>프로젝트 셋팅 &amp; SDK 설치\n<img src=\"https://i.imgur.com/eo5T9It.png\" alt=\"\"></li>\n</ul>\n</li>\n<li>\n<p>Simulator 셋팅</p>\n<ul>\n<li>iOS simulator 실행\n<img src=\"https://i.imgur.com/vK85Ojw.png\" alt=\"\"></li>\n<li>빠릿 빠릿한 iphone 12 max\n<img src=\"https://i.imgur.com/56dqoww.jpg\" alt=\"\"></li>\n<li>코드 빌드 및 실행\n<img src=\"https://i.imgur.com/al6lAuY.png\" alt=\"\">\n실행한 iphone이 안보이면\n<code>sudo xcode-select --switch /Applications/Xcode.app/Contents/Developer</code></li>\n</ul>\n</li>\n</ol>\n",
      "id": 15
    },
    {
      "path": "5-Flutter/2-Widget.md",
      "url": "5-Flutter/2-Widget.html",
      "content": "Chapter 2. Widget\n===\n###### tags: `Flutter` `Stateless Widget` `Stateful Widget`\n\n- Flutter Widget이란\n    - App bar, text, icon, button 등 화면을 구성하는 컴포넌트 단위\n    ![](https://i.imgur.com/Sb7DlQE.png)\n\n    - Layer 및 위치를 담당\n    ![](https://i.imgur.com/vCN0IF9.png)\n\n    - Application 전체도 하나의 위젯\n\n- LifeCycle\n    ![](https://i.imgur.com/llH7dRF.png)\n    - https://mobikul.com/lifecycle-of-a-flutter-app/\n    \n- 기본 구조\n    - Application -> MaterialApp -> Page -> Scaffold\n    ![](https://i.imgur.com/RQwhPsq.png)\n    - MaterialApp: https://api.flutter.dev/flutter/material/MaterialApp-class.html\n    - Scaffold: https://api.flutter.dev/flutter/material/Scaffold-class.html\n\n- Widget 종류\n    - Stateful Widget:\n        - 계속 움직이며 변화가 생길 수 있는 동적인 위젯 \n        - setState함수를 이용하여 stateful 컴포넌트에 존재하는 state 변수를 수정하고 rerender 진행\n        ```java\n        class HomePage extends StatefulWidget {\n          _HomePageState createState() => new _HomePageState();\n        }\n        class _HomePageState extends State<HomePage> {\n          @override\n          void initState() {\n            super.initState();\n          }\n\n          @override\n          Widget build(context) {\n            return Center(\n            );\n          }\n        }\n        ```\n    - Stateless Widget:\n        - 변화가 없는 정적인 위젯\n        - 순수 UI 목적을 가진 컴포넌트로 변동하는 state를 내포할 수 없음\n        ```java\n        class UserPage extends StatelessWidget {\n          @override\n          Widget build(context) {\n            return Center(\n            );\n          }\n        }\n        ```\n        ",
      "html": "<h1 id=\"chapter-2.-widget\">Chapter 2. Widget <a class=\"heading-anchor-permalink\" href=\"#chapter-2.-widget\">#</a></h1>\n<h6 id=\"tags%3A-flutter-stateless-widget-stateful-widget\">tags: <code>Flutter</code> <code>Stateless Widget</code> <code>Stateful Widget</code> <a class=\"heading-anchor-permalink\" href=\"#tags%3A-flutter-stateless-widget-stateful-widget\">#</a></h6>\n<ul>\n<li>\n<p>Flutter Widget이란</p>\n<ul>\n<li>\n<p>App bar, text, icon, button 등 화면을 구성하는 컴포넌트 단위\n<img src=\"https://i.imgur.com/Sb7DlQE.png\" alt=\"\"></p>\n</li>\n<li>\n<p>Layer 및 위치를 담당\n<img src=\"https://i.imgur.com/vCN0IF9.png\" alt=\"\"></p>\n</li>\n<li>\n<p>Application 전체도 하나의 위젯</p>\n</li>\n</ul>\n</li>\n<li>\n<p>LifeCycle\n<img src=\"https://i.imgur.com/llH7dRF.png\" alt=\"\"></p>\n<ul>\n<li><a href=\"https://mobikul.com/lifecycle-of-a-flutter-app/\">https://mobikul.com/lifecycle-of-a-flutter-app/</a></li>\n</ul>\n</li>\n<li>\n<p>기본 구조</p>\n<ul>\n<li>Application -&gt; MaterialApp -&gt; Page -&gt; Scaffold\n<img src=\"https://i.imgur.com/RQwhPsq.png\" alt=\"\"></li>\n<li>MaterialApp: <a href=\"https://api.flutter.dev/flutter/material/MaterialApp-class.html\">https://api.flutter.dev/flutter/material/MaterialApp-class.html</a></li>\n<li>Scaffold: <a href=\"https://api.flutter.dev/flutter/material/Scaffold-class.html\">https://api.flutter.dev/flutter/material/Scaffold-class.html</a></li>\n</ul>\n</li>\n<li>\n<p>Widget 종류</p>\n<ul>\n<li>Stateful Widget:\n<ul>\n<li>계속 움직이며 변화가 생길 수 있는 동적인 위젯</li>\n<li>setState함수를 이용하여 stateful 컴포넌트에 존재하는 state 변수를 수정하고 rerender 진행</li>\n</ul>\n<pre><code class=\"language-java\">class HomePage extends StatefulWidget {\n  _HomePageState createState() =&gt; new _HomePageState();\n}\nclass _HomePageState extends State&lt;HomePage&gt; {\n  @override\n  void initState() {\n    super.initState();\n  }\n\n  @override\n  Widget build(context) {\n    return Center(\n    );\n  }\n}\n</code></pre>\n</li>\n<li>Stateless Widget:\n<ul>\n<li>변화가 없는 정적인 위젯</li>\n<li>순수 UI 목적을 가진 컴포넌트로 변동하는 state를 내포할 수 없음</li>\n</ul>\n<pre><code class=\"language-java\">class UserPage extends StatelessWidget {\n  @override\n  Widget build(context) {\n    return Center(\n    );\n  }\n}\n</code></pre>\n</li>\n</ul>\n</li>\n</ul>\n",
      "id": 16
    },
    {
      "path": "5-Flutter/3-Assets.md",
      "url": "5-Flutter/3-Assets.html",
      "content": "Chapter3. Assets\n===\n\n###### tags: `Flutter`\n\n- image파일이 담길 폴더 생성\n\n    ![](https://i.imgur.com/tzxdNV8.png)\n    \n- pubspec.yaml파일에 assets 설정\n\n    ![](https://i.imgur.com/xmnVqms.png)\n\n- Pub get click!\n\n    ![](https://i.imgur.com/QZXGHLb.png)\n    \n:exclamation:혹시 이래도 이미지를 찾을 수 없다고 나오면 앱을 다시 실행해 본다",
      "html": "<h1 id=\"chapter3.-assets\">Chapter3. Assets <a class=\"heading-anchor-permalink\" href=\"#chapter3.-assets\">#</a></h1>\n<h6 id=\"tags%3A-flutter\">tags: <code>Flutter</code> <a class=\"heading-anchor-permalink\" href=\"#tags%3A-flutter\">#</a></h6>\n<ul>\n<li>\n<p>image파일이 담길 폴더 생성</p>\n<p><img src=\"https://i.imgur.com/tzxdNV8.png\" alt=\"\"></p>\n</li>\n<li>\n<p>pubspec.yaml파일에 assets 설정</p>\n<p><img src=\"https://i.imgur.com/xmnVqms.png\" alt=\"\"></p>\n</li>\n<li>\n<p>Pub get click!</p>\n<p><img src=\"https://i.imgur.com/QZXGHLb.png\" alt=\"\"></p>\n</li>\n</ul>\n<p>:exclamation:혹시 이래도 이미지를 찾을 수 없다고 나오면 앱을 다시 실행해 본다</p>\n",
      "id": 17
    },
    {
      "path": "5-Flutter/4-Http Request.md",
      "url": "5-Flutter/4-Http Request.html",
      "content": "Http Requester\n===\n\n###### tags: `flutter`\n\n- Dependency\n    ```yaml\n    dependencies:\n        http: ^0.13.1 # latest version\n    ```\n    \n- Data Object\n    ```java\n    class Post {\n      final int userId;\n      final int id;\n      final String title;\n      final String body;\n\n      Post({this.userId, this.id, this.title, this.body});\n\n      factory Post.fromJson(Map<String, dynamic> json) {\n        return Post(\n          userId: json['userId'],\n          id: json['id'],\n          title: json['title'],\n          body: json['body'],\n        );\n      }\n    }\n    ```\n\n- Http Requester & DTO transform\n    ```java\n    import 'package:has_admin/auxilary/post.dto.dart';\n    import 'dart:convert';\n    import 'package:http/http.dart' as http;\n\n    class PostRequester {\n      Future<List<Post>> fetchPost() async {\n        http.Response response = await http.get(\n            Uri.parse('https://jsonplaceholder.typicode.com/posts'),\n            headers: {\"Accept\": \"application/json\"});\n        if (response.statusCode == 200) {\n          return json.decode(response.body).map<Post>((post) => Post.fromJson(post)).toList();\n        } else {\n          throw Exception('Failed to load post');\n        }\n      }\n    }\n    ```\n\n- Widget\n    ```java\n    class _HomePageState extends State<HomePage> {\n      String get title => 'Home Page';\n      Future<List<Post>> posts;\n      PostRequester requester = new PostRequester();\n\n      @override\n      void initState() {\n        super.initState();\n        posts = requester.fetchPost();\n      }\n\n      @override\n      Widget build(context) {\n        return Center(\n          child: FutureBuilder<List<Post>>(\n            future: posts,\n            builder: (context, snapshot) {\n              return ListView.builder(\n                itemCount: snapshot.data.length,\n                itemBuilder: (context, index) {\n                  Post post = snapshot.data[index];\n                  return Row(\n                    children: [\n                      Expanded(\n                        flex: 3,\n                        child: Text(post.title)\n                      ),\n                      Expanded(\n                        flex: 7,\n                        child: Text(post.body)\n                      )\n                    ],\n                  );\n                },\n              );\n            }\n          )\n        );\n      }\n    }\n    ```",
      "html": "<h1 id=\"http-requester\">Http Requester <a class=\"heading-anchor-permalink\" href=\"#http-requester\">#</a></h1>\n<h6 id=\"tags%3A-flutter\">tags: <code>flutter</code> <a class=\"heading-anchor-permalink\" href=\"#tags%3A-flutter\">#</a></h6>\n<ul>\n<li>\n<p>Dependency</p>\n<pre><code class=\"language-yaml\">dependencies:\n    http: ^0.13.1 # latest version\n</code></pre>\n</li>\n<li>\n<p>Data Object</p>\n<pre><code class=\"language-java\">class Post {\n  final int userId;\n  final int id;\n  final String title;\n  final String body;\n\n  Post({this.userId, this.id, this.title, this.body});\n\n  factory Post.fromJson(Map&lt;String, dynamic&gt; json) {\n    return Post(\n      userId: json['userId'],\n      id: json['id'],\n      title: json['title'],\n      body: json['body'],\n    );\n  }\n}\n</code></pre>\n</li>\n<li>\n<p>Http Requester &amp; DTO transform</p>\n<pre><code class=\"language-java\">import 'package:has_admin/auxilary/post.dto.dart';\nimport 'dart:convert';\nimport 'package:http/http.dart' as http;\n\nclass PostRequester {\n  Future&lt;List&lt;Post&gt;&gt; fetchPost() async {\n    http.Response response = await http.get(\n        Uri.parse('https://jsonplaceholder.typicode.com/posts'),\n        headers: {&quot;Accept&quot;: &quot;application/json&quot;});\n    if (response.statusCode == 200) {\n      return json.decode(response.body).map&lt;Post&gt;((post) =&gt; Post.fromJson(post)).toList();\n    } else {\n      throw Exception('Failed to load post');\n    }\n  }\n}\n</code></pre>\n</li>\n<li>\n<p>Widget</p>\n<pre><code class=\"language-java\">class _HomePageState extends State&lt;HomePage&gt; {\n  String get title =&gt; 'Home Page';\n  Future&lt;List&lt;Post&gt;&gt; posts;\n  PostRequester requester = new PostRequester();\n\n  @override\n  void initState() {\n    super.initState();\n    posts = requester.fetchPost();\n  }\n\n  @override\n  Widget build(context) {\n    return Center(\n      child: FutureBuilder&lt;List&lt;Post&gt;&gt;(\n        future: posts,\n        builder: (context, snapshot) {\n          return ListView.builder(\n            itemCount: snapshot.data.length,\n            itemBuilder: (context, index) {\n              Post post = snapshot.data[index];\n              return Row(\n                children: [\n                  Expanded(\n                    flex: 3,\n                    child: Text(post.title)\n                  ),\n                  Expanded(\n                    flex: 7,\n                    child: Text(post.body)\n                  )\n                ],\n              );\n            },\n          );\n        }\n      )\n    );\n  }\n}\n</code></pre>\n</li>\n</ul>\n",
      "id": 18
    },
    {
      "path": "99-ETC/CloudStorage.md",
      "url": "99-ETC/CloudStorage.html",
      "content": "Free Cloud Storage\n===\n\n- 저렴한 DB 비교\n    - Constraints\n        - Azure, AWS, Google의 Free tier는 제외했다. (필자는 1년 무료 기간이 전부 만료된 상태)\n        - 서울 혹은 아시아 리전 기준이다.\n        - 가장 저렴한것을 기준으로 별도 백업과 같은 서비스 제공은 고려하지 않았다.\n    - Azure SQL DB vs AWS Dynamo DB vs Google Firestore\n        - Azure SQL DB\n          ![](https://i.imgur.com/xT4pmXd.png)\n          별도 무료 스토리지 제공은 없지만 1기가당 가격이 저렴하며 읽기/쓰기 요청에 대한 요금이 없다.\n\n        - AWS Dynamo DB\n          ![](https://i.imgur.com/j0wWA8N.png)\n          25기가까지 스토리지 비용이 무료이지만 읽기/쓰기 요청에 대한 과금이 있다.\n\n        - Google Firestore\n          ![](https://i.imgur.com/qif8uds.png)\n          1기가의 적은 스토리지만 무료로 제공되며 읽기/쓰기에 대한 일일 무료 할당량이 존재한다.\n- 저렴한 File Storage 비교\n    - Azure Blob Storage vs AWS S3 vs Google \n        - Azure Blob Storage\n          ![](https://i.imgur.com/mzJe3fE.png)\n          ![](https://i.imgur.com/fKefyLo.png)\n        - AWS S3\n          ![](https://i.imgur.com/VrElTuB.png)\n          ![](https://i.imgur.com/C7lgVqU.png)\n        - Google Cloud Storage\n          ![](https://i.imgur.com/TKaZDeF.png)\n      \n\n- Conclusion\n    - DB: 개발 서버 및 사용량이 적은 환경이면 Firestore가 적합하며 스토리지가 25기가 정도 필요하다 싶으면 AWS를 그것을 초과하면 Azure를 사용하면 될것 같다.\n    - File Storage: 금액은 대동소이하다. Google은 무료사용 용량을 제공하지만 다른 storage보다 조금 비싸며 Azure와 AWS중에는 Azure가 조금 더 저렴하다.",
      "html": "<h1 id=\"free-cloud-storage\">Free Cloud Storage <a class=\"heading-anchor-permalink\" href=\"#free-cloud-storage\">#</a></h1>\n<ul>\n<li>\n<p>저렴한 DB 비교</p>\n<ul>\n<li>Constraints\n<ul>\n<li>Azure, AWS, Google의 Free tier는 제외했다. (필자는 1년 무료 기간이 전부 만료된 상태)</li>\n<li>서울 혹은 아시아 리전 기준이다.</li>\n<li>가장 저렴한것을 기준으로 별도 백업과 같은 서비스 제공은 고려하지 않았다.</li>\n</ul>\n</li>\n<li>Azure SQL DB vs AWS Dynamo DB vs Google Firestore\n<ul>\n<li>\n<p>Azure SQL DB\n<img src=\"https://i.imgur.com/xT4pmXd.png\" alt=\"\">\n별도 무료 스토리지 제공은 없지만 1기가당 가격이 저렴하며 읽기/쓰기 요청에 대한 요금이 없다.</p>\n</li>\n<li>\n<p>AWS Dynamo DB\n<img src=\"https://i.imgur.com/j0wWA8N.png\" alt=\"\">\n25기가까지 스토리지 비용이 무료이지만 읽기/쓰기 요청에 대한 과금이 있다.</p>\n</li>\n<li>\n<p>Google Firestore\n<img src=\"https://i.imgur.com/qif8uds.png\" alt=\"\">\n1기가의 적은 스토리지만 무료로 제공되며 읽기/쓰기에 대한 일일 무료 할당량이 존재한다.</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>저렴한 File Storage 비교</p>\n<ul>\n<li>Azure Blob Storage vs AWS S3 vs Google\n<ul>\n<li>Azure Blob Storage\n<img src=\"https://i.imgur.com/mzJe3fE.png\" alt=\"\">\n<img src=\"https://i.imgur.com/fKefyLo.png\" alt=\"\"></li>\n<li>AWS S3\n<img src=\"https://i.imgur.com/VrElTuB.png\" alt=\"\">\n<img src=\"https://i.imgur.com/C7lgVqU.png\" alt=\"\"></li>\n<li>Google Cloud Storage\n<img src=\"https://i.imgur.com/TKaZDeF.png\" alt=\"\"></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>Conclusion</p>\n<ul>\n<li>DB: 개발 서버 및 사용량이 적은 환경이면 Firestore가 적합하며 스토리지가 25기가 정도 필요하다 싶으면 AWS를 그것을 초과하면 Azure를 사용하면 될것 같다.</li>\n<li>File Storage: 금액은 대동소이하다. Google은 무료사용 용량을 제공하지만 다른 storage보다 조금 비싸며 Azure와 AWS중에는 Azure가 조금 더 저렴하다.</li>\n</ul>\n</li>\n</ul>\n",
      "id": 19
    },
    {
      "path": "99-ETC/GithubPage.md",
      "url": "99-ETC/GithubPage.html",
      "content": "Github Page\n===\n\n- 기본적으로 gh-pages 브랜치나 특정 브랜치의 docs폴더에 있는\n  static 컨텐츠를 기반으로 호스팅을 하게 되며\n  url은 https://[github ID].github.io/[project name] 형식이 됩니다.\n  \n- 간혹 public path에 있는 리소스를 찾지 못하는 경우가 있습니다.\n  ![](https://i.imgur.com/qBXnghA.png)\n  그럴 때는 3가지를 확인해 주시면 됩니다.\n  1. Webpack config의 public path\n  2. package.json의 homepage 필드\n  3. react-router나 vue-router의 baseUrl\n  저는 위 3가지 항목을 relative path인 `./`로 셋팅해줍니다.\n\n- 그리고 나서 githubpage의 setting에서\n  ![](https://i.imgur.com/GdV2TaJ.png)\n  위 항목을 설정해 주면 page가 호스팅되는것을 확인할 수 있습니다.\n  \n- !주의\n  1. private 패키지는 호스팅하는데 과금이 있습니다.\n  2. dns셋팅시 public폴더 밑에 CNAME파일을 생성하여 안에 domain정보를 넣어주시면 됩니다.\n",
      "html": "<h1 id=\"github-page\">Github Page <a class=\"heading-anchor-permalink\" href=\"#github-page\">#</a></h1>\n<ul>\n<li>\n<p>기본적으로 gh-pages 브랜치나 특정 브랜치의 docs폴더에 있는\nstatic 컨텐츠를 기반으로 호스팅을 하게 되며\nurl은 https://[github ID].github.io/[project name] 형식이 됩니다.</p>\n</li>\n<li>\n<p>간혹 public path에 있는 리소스를 찾지 못하는 경우가 있습니다.\n<img src=\"https://i.imgur.com/qBXnghA.png\" alt=\"\">\n그럴 때는 3가지를 확인해 주시면 됩니다.</p>\n<ol>\n<li>Webpack config의 public path</li>\n<li>package.json의 homepage 필드</li>\n<li>react-router나 vue-router의 baseUrl\n저는 위 3가지 항목을 relative path인 <code>./</code>로 셋팅해줍니다.</li>\n</ol>\n</li>\n<li>\n<p>그리고 나서 githubpage의 setting에서\n<img src=\"https://i.imgur.com/GdV2TaJ.png\" alt=\"\">\n위 항목을 설정해 주면 page가 호스팅되는것을 확인할 수 있습니다.</p>\n</li>\n<li>\n<p>!주의</p>\n<ol>\n<li>private 패키지는 호스팅하는데 과금이 있습니다.</li>\n<li>dns셋팅시 public폴더 밑에 CNAME파일을 생성하여 안에 domain정보를 넣어주시면 됩니다.</li>\n</ol>\n</li>\n</ul>\n",
      "id": 20
    },
    {
      "path": "99-ETC/MQvsKafka.md",
      "url": "99-ETC/MQvsKafka.html",
      "content": "# MQ & Kafka\n\n---\n***Kafka use cases***\n\n- Messaging System\n- Activity Tracking\n- Gather metrics from many different locations\n- Application logs gathering\n- Stream processing\n- De-coupling of system dependencies\n- Integration with Spark, Flink, Storm, Hadoop, and other Big Data technologies\n\n---\n\n---\n***MQ vs Kafka***\n\nMQ\n- consume된 message는 큐에서 바로 삭제\n- message replay 불가능\n- AMQP 기반: Message Broker를 통해 queue와 통신하기 용이\n- 메시지를 받았을때 or 처리하였을 때 acknowlegment 발생\n- 프로세스 실패하면 새로운 message로 queue에 추가\n\nKafka\n- consume된 record는 retention 조건(time or size limit)에 따라 삭제\n- record replay 가능\n- TCP/IP 기반\n- Offset으로 가장 마지막에 처리한 record를 tracking\n- 프로세스 실패하면 offset을 움직이지 않음\n\nSimple Message Queue\nComplicated Kafka\n\n---",
      "html": "<h1 id=\"mq-%26-kafka\">MQ &amp; Kafka <a class=\"heading-anchor-permalink\" href=\"#mq-%26-kafka\">#</a></h1>\n<hr>\n<p><em><strong>Kafka use cases</strong></em></p>\n<ul>\n<li>Messaging System</li>\n<li>Activity Tracking</li>\n<li>Gather metrics from many different locations</li>\n<li>Application logs gathering</li>\n<li>Stream processing</li>\n<li>De-coupling of system dependencies</li>\n<li>Integration with Spark, Flink, Storm, Hadoop, and other Big Data technologies</li>\n</ul>\n<hr>\n<hr>\n<p><em><strong>MQ vs Kafka</strong></em></p>\n<p>MQ</p>\n<ul>\n<li>consume된 message는 큐에서 바로 삭제</li>\n<li>message replay 불가능</li>\n<li>AMQP 기반: Message Broker를 통해 queue와 통신하기 용이</li>\n<li>메시지를 받았을때 or 처리하였을 때 acknowlegment 발생</li>\n<li>프로세스 실패하면 새로운 message로 queue에 추가</li>\n</ul>\n<p>Kafka</p>\n<ul>\n<li>consume된 record는 retention 조건(time or size limit)에 따라 삭제</li>\n<li>record replay 가능</li>\n<li>TCP/IP 기반</li>\n<li>Offset으로 가장 마지막에 처리한 record를 tracking</li>\n<li>프로세스 실패하면 offset을 움직이지 않음</li>\n</ul>\n<p>Simple Message Queue\nComplicated Kafka</p>\n<hr>\n",
      "id": 21
    }
  ]
}